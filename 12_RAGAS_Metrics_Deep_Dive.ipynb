{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "85fd63e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ok\n"
     ]
    }
   ],
   "source": [
    "print(\"ok\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f6a00839",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fa53e778",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ All imports successful\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import asyncio\n",
    "import json\n",
    "\n",
    "from langchain_openai import AzureChatOpenAI\n",
    "from langchain_openai import AzureOpenAIEmbeddings\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "\n",
    "from ragas import SingleTurnSample, EvaluationDataset, evaluate\n",
    "from ragas.metrics import (\n",
    "    Faithfulness,\n",
    "    ResponseRelevancy,\n",
    "    LLMContextPrecisionWithReference,\n",
    "    LLMContextRecall,\n",
    "    ContextEntityRecall,\n",
    "    NoiseSensitivity\n",
    ")\n",
    "\n",
    "from ragas.llms import LangchainLLMWrapper\n",
    "from ragas.embeddings import LangchainEmbeddingsWrapper\n",
    "\n",
    "print(\"‚úÖ All imports successful\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "74a62607",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ LLM initialized: gpt-4o\n",
      "‚úÖ Embeddings initialized: text-embedding-ada-002\n",
      "‚úÖ RAGAS wrappers ready\n"
     ]
    }
   ],
   "source": [
    "llm = AzureChatOpenAI(\n",
    "    azure_endpoint=os.getenv(\"AZURE_OPENAI_ENDPOINT\"),\n",
    "    api_key=os.getenv(\"AZURE_OPENAI_API_KEY\"),\n",
    "    deployment_name=os.getenv(\"AZURE_OPENAI_DEPLOYMENT_NAME\"),\n",
    "    api_version=os.getenv(\"AZURE_OPENAI_API_VERSION\"),\n",
    ")\n",
    "\n",
    "embeddings = AzureOpenAIEmbeddings(\n",
    "    azure_endpoint=os.getenv(\"AZURE_OPENAI_ENDPOINT\"),\n",
    "    api_key=os.getenv(\"AZURE_OPENAI_API_KEY\"),\n",
    "    api_version=os.getenv(\"AZURE_OPENAI_API_VERSION\"),\n",
    "    model=os.getenv(\"AZURE_OPENAI_EMBEDDING_DEPLOYMENT_NAME\")\n",
    ")\n",
    "\n",
    "ragas_llm = LangchainLLMWrapper(llm)\n",
    "ragas_embeddings = LangchainEmbeddingsWrapper(embeddings)\n",
    "\n",
    "print(\"‚úÖ LLM initialized: gpt-4o\")\n",
    "print(\"‚úÖ Embeddings initialized: text-embedding-ada-002\")\n",
    "print(\"‚úÖ RAGAS wrappers ready\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "99b737f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_async(coro):\n",
    "    try:\n",
    "        loop = asyncio.get_event_loop()\n",
    "        if loop.is_running():\n",
    "            import nest_asyncio\n",
    "            nest_asyncio.apply()\n",
    "            return loop.run_until_complete(coro)\n",
    "        else:\n",
    "            return asyncio.run(coro)\n",
    "    except RuntimeError:\n",
    "        return asyncio.run(coro)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "308bc7d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìù Response to evaluate:\n",
      "   'The first Super Bowl was held on January 15, 1967 in Los Angeles. It was a sunny day with clear skies.'\n",
      "\n",
      "üìö Retrieved context:\n",
      "   'The First AFL-NFL World Championship Game was played on January 15, 1967, at the Los Angeles Memorial Coliseum in Los Angeles, California.'\n"
     ]
    }
   ],
   "source": [
    "test_response = \"The first Super Bowl was held on January 15, 1967 in Los Angeles. It was a sunny day with clear skies.\"\n",
    "test_context = [\n",
    "    \"The First AFL-NFL World Championship Game was played on January 15, 1967, at the Los Angeles Memorial Coliseum in Los Angeles, California.\"\n",
    "]\n",
    "print(\"üìù Response to evaluate:\")\n",
    "print(f\"   '{test_response}'\")\n",
    "print(\"\\nüìö Retrieved context:\")\n",
    "print(f\"   '{test_context[0]}'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "97d13c5d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîç STEP 1: Extracted Claims from Response\n",
      "==================================================\n",
      "1. The First AFL-NFL World Championship Game was played on January 15, 1967.  \n",
      "2. The game took place at the Los Angeles Memorial Coliseum.  \n",
      "3. The game was held in Los Angeles, California.\n"
     ]
    }
   ],
   "source": [
    "claim_extraction_prompt = ChatPromptTemplate.from_template(\"\"\"\n",
    "Given the following response, extract ALL factual claims as a numbered list.\n",
    "Each claim should be a single, verifiable statement.\n",
    "\n",
    "Response: {response}\n",
    "\n",
    "Extract each factual claim:\n",
    "\"\"\")\n",
    "\n",
    "claim_chain = claim_extraction_prompt | llm | StrOutputParser()\n",
    "extracted_claim_raw = claim_chain.invoke({\"response\":test_context})\n",
    "\n",
    "print(\"üîç STEP 1: Extracted Claims from Response\")\n",
    "print(\"=\" * 50)\n",
    "print(extracted_claim_raw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a35556a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìã Claims to verify:\n",
      "   1. The first Super Bowl was held on January 15, 1967\n",
      "   2. The first Super Bowl was held in Los Angeles\n",
      "   3. It was a sunny day\n",
      "   4. There were clear skies\n"
     ]
    }
   ],
   "source": [
    "claims = [\n",
    "    \"The first Super Bowl was held on January 15, 1967\",\n",
    "    \"The first Super Bowl was held in Los Angeles\",\n",
    "    \"It was a sunny day\",\n",
    "    \"There were clear skies\"\n",
    "]\n",
    "print(\"üìã Claims to verify:\")\n",
    "for i, claim in enumerate(claims, 1):\n",
    "    print(f\"   {i}. {claim}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ea2925a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîç STEP 2: Verifying Each Claim Against Context\n",
      "============================================================\n",
      "\n",
      "‚úÖ Claims: The first Super Bowl was held on January 15, 1967\n",
      "    Result: **SUPPORTED**\n",
      "\n",
      "**Explanation:** The context states that the First AFL-NFL World Championship Game wa...\n",
      "\n",
      "‚úÖ Claims: The first Super Bowl was held in Los Angeles\n",
      "    Result: SUPPORTED\n",
      "\n",
      "Explanation: The context states that the First AFL-NFL World Championship Game (the event...\n",
      "\n",
      "‚ùå Claims: It was a sunny day\n",
      "    Result: **NOT SUPPORTED**\n",
      "\n",
      "**Explanation:** The context provides information about the date, location, and e...\n",
      "\n",
      "‚ùå Claims: There were clear skies\n",
      "    Result: NOT SUPPORTED\n",
      "\n",
      "Explanation: The context does not provide any information about the weather condition...\n"
     ]
    }
   ],
   "source": [
    "verification_prompt = ChatPromptTemplate.from_template(\"\"\"\n",
    "Given the following context and claim, determine if the claim is SUPPORTED by the context.\n",
    "\n",
    "Context: {context}\n",
    "\n",
    "Claim: {claim}\n",
    "\n",
    "Answer with:\n",
    "- \"SUPPORTED\" if the claim can be verified from the context\n",
    "- \"NOT SUPPORTED\" if the claim cannot be verified or contradicts the context\n",
    "\n",
    "Also provide a brief explanation.\n",
    "\n",
    "Verdict:\n",
    "\"\"\")\n",
    "\n",
    "verify_claims = verification_prompt | llm | StrOutputParser()\n",
    "\n",
    "print(\"üîç STEP 2: Verifying Each Claim Against Context\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "verification_results = []\n",
    "for claim in claims:\n",
    "    result = verify_claims.invoke({\n",
    "        \"context\":test_context[0],\n",
    "        \"claim\":claim\n",
    "    })\n",
    "    is_supported = \"SUPPORTED\" in result.upper() and \"NOT SUPPORTED\" not in result.upper()\n",
    "    verification_results.append({\n",
    "        \"claim\":claim,\n",
    "        \"supported\": is_supported,\n",
    "        \"explanation\":result,\n",
    "    })\n",
    "    status = \"‚úÖ\" if is_supported else \"‚ùå\"\n",
    "    print(f\"\\n{status} Claims: {claim}\")\n",
    "    print(f\"    Result: {result[:100]}...\" if len(result)>100 else f\"    Result: {result[:100]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "57d0bb58",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üìä Claim Verification Summary\n",
      "================================================================================\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Clain</th>\n",
       "      <th>Supported?</th>\n",
       "      <th>Reason</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>The first Super Bowl was held on January 15, 1967</td>\n",
       "      <td>‚úÖ Yes</td>\n",
       "      <td>Found in context</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>The first Super Bowl was held in Los Angeles</td>\n",
       "      <td>‚úÖ Yes</td>\n",
       "      <td>Found in context</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>It was a sunny day</td>\n",
       "      <td>‚ùå No</td>\n",
       "      <td>HALLUCINATION - Not in context!</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>There were clear skies</td>\n",
       "      <td>‚ùå No</td>\n",
       "      <td>HALLUCINATION - Not in context!</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               Clain  ...                           Reason\n",
       "0  The first Super Bowl was held on January 15, 1967  ...                 Found in context\n",
       "1       The first Super Bowl was held in Los Angeles  ...                 Found in context\n",
       "2                                 It was a sunny day  ...  HALLUCINATION - Not in context!\n",
       "3                             There were clear skies  ...  HALLUCINATION - Not in context!\n",
       "\n",
       "[4 rows x 3 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"\\nüìä Claim Verification Summary\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "df_verification = pd.DataFrame([\n",
    "    {\n",
    "        \"Clain\": r['claim'],\n",
    "        \"Supported?\":\"‚úÖ Yes\" if r[\"supported\"] else \"‚ùå No\",\n",
    "        \"Reason\":\"Found in context\" if r['supported'] else \"HALLUCINATION - Not in context!\"\n",
    "\n",
    "    }\n",
    "    for r in verification_results\n",
    "])\n",
    "df_verification.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "bfa0ed3b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üî¢ STEP 3: Calculate Faithfulness Score\n",
      "==================================================\n",
      "\n",
      "   Supported claims: 2\n",
      "   Total claims: 4\n",
      "\n",
      "   Formula: Faithfulness = 2 / 4\n",
      "\n",
      "   üìä Manual Faithfulness Score: 0.50\n"
     ]
    }
   ],
   "source": [
    "supported_count = sum(1 for r in verification_results if r['supported'])\n",
    "total_claims = len(verification_results)\n",
    "\n",
    "manual_faithfulness = supported_count/total_claims\n",
    "\n",
    "print(\"üî¢ STEP 3: Calculate Faithfulness Score\")\n",
    "print(\"=\" * 50)\n",
    "print(f\"\\n   Supported claims: {supported_count}\")\n",
    "print(f\"   Total claims: {total_claims}\")\n",
    "print(f\"\\n   Formula: Faithfulness = {supported_count} / {total_claims}\")\n",
    "print(f\"\\n   üìä Manual Faithfulness Score: {manual_faithfulness:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e3abf02",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üî¨ RAGAS Faithfulness Result\n",
      "==================================================\n",
      "\n",
      "   Manual calculation:  0.50\n",
      "   RAGAS metric score:  0.50\n",
      "\n",
      "   Difference: 0.00\n"
     ]
    }
   ],
   "source": [
    "faithfulness_sample = SingleTurnSample(\n",
    "    user_input=\"When was the first Super Bowl?\",\n",
    "    response=test_response,\n",
    "    retrieved_contexts=test_context\n",
    ")\n",
    "faithfulness_metric = Faithfulness(llm=ragas_llm)\n",
    "ragas_faithfulness = run_async(faithfulness_metric.single_turn_ascore(faithfulness_sample))\n",
    "\n",
    "print(\"üî¨ RAGAS Faithfulness Result\")\n",
    "print(\"=\" * 50)\n",
    "print(f\"\\n   Manual calculation:  {manual_faithfulness:.2f}\")\n",
    "print(f\"   RAGAS metric score:  {ragas_faithfulness:.2f}\")\n",
    "print(f\"\\n   Difference: {abs(manual_faithfulness - ragas_faithfulness):.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "7f7f580f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìä Faithfulness Comparison: Different Scenarios\n",
      "======================================================================\n",
      "\n",
      "Perfect Faithfulness (No hallucinations): \n",
      "   Response: The first Super Bowl was played on January 15, 1967 at the Los Angeles Memorial \n",
      "Score: 1.00\n",
      "\n",
      "Partial Faithfulness (Some hallucinations): \n",
      "   Response: The first Super Bowl was on January 15, 1967. The Green Bay Packers won 35-10 wi\n",
      "Score: 0.33\n",
      "\n",
      "Zero Faithfulness (Complete hallucination): \n",
      "   Response: The first Super Bowl was held in Miami in 1970 and attracted over 100,000 specta\n",
      "Score: 0.00\n"
     ]
    }
   ],
   "source": [
    "faithfulness_examples = [\n",
    "    {\n",
    "        \"name\": \"Perfect Faithfulness (No hallucinations)\",\n",
    "        \"response\": \"The first Super Bowl was played on January 15, 1967 at the Los Angeles Memorial Coliseum.\",\n",
    "        \"context\": [\"The First AFL-NFL World Championship Game was played on January 15, 1967, at the Los Angeles Memorial Coliseum.\"]\n",
    "    },\n",
    "    {\n",
    "        \"name\": \"Partial Faithfulness (Some hallucinations)\",\n",
    "        \"response\": \"The first Super Bowl was on January 15, 1967. The Green Bay Packers won 35-10 with Bart Starr as MVP.\",\n",
    "        \"context\": [\"The First AFL-NFL World Championship Game was played on January 15, 1967.\"]\n",
    "    },\n",
    "    {\n",
    "        \"name\": \"Zero Faithfulness (Complete hallucination)\",\n",
    "        \"response\": \"The first Super Bowl was held in Miami in 1970 and attracted over 100,000 spectators.\",\n",
    "        \"context\": [\"The First AFL-NFL World Championship Game was played on January 15, 1967, at the Los Angeles Memorial Coliseum.\"]\n",
    "    }\n",
    "]\n",
    "\n",
    "print(\"üìä Faithfulness Comparison: Different Scenarios\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "for example in faithfulness_examples:\n",
    "    sample = SingleTurnSample(\n",
    "        user_input=\"Tell me about the first Super Bowl\",\n",
    "        response=example[\"response\"],\n",
    "        retrieved_contexts=example['context']\n",
    "    )\n",
    "    score = run_async(faithfulness_metric.single_turn_ascore(sample))\n",
    "\n",
    "    print(f\"\\n{example['name']}: \")\n",
    "    print(f\"   Response: {example['response'][:80] if len(example['response'])> 80 else example['response']}\")\n",
    "    print(f\"Score: { score:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "0f695a56",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìù Original Question:\n",
      "   'When was the first Super Bowl?'\n",
      "\n",
      "üìù Answer to Evaluate:\n",
      "   'The first Super Bowl was held on January 15, 1967'\n"
     ]
    }
   ],
   "source": [
    "original_question = \"When was the first Super Bowl?\"\n",
    "test_answer = \"The first Super Bowl was held on January 15, 1967\"\n",
    "\n",
    "print(\"üìù Original Question:\")\n",
    "print(f\"   '{original_question}'\")\n",
    "print(\"\\nüìù Answer to Evaluate:\")\n",
    "print(f\"   '{test_answer}'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "dcc34bcc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîç STEP 1: Generated Hypothetical Questions\n",
      "==================================================\n",
      "1. When was the first Super Bowl held?  \n",
      "2. What significant sports event took place on January 15, 1967?  \n",
      "3. Can you tell me the date of the inaugural Super Bowl?  \n"
     ]
    }
   ],
   "source": [
    "question_gen_prompt = ChatPromptTemplate.from_template(\"\"\"\n",
    "Given the following answer, generate exactly 3 different questions that this answer would be a good response to.\n",
    "The questions should be varied but all answerable by this response.\n",
    "\n",
    "Answer: {answer}\n",
    "\n",
    "Generate 3 questions (one per line):\n",
    "1.\n",
    "2.\n",
    "3.\n",
    "\"\"\")\n",
    "\n",
    "question_gen_chain = question_gen_prompt | llm | StrOutputParser()\n",
    "\n",
    "generated_question = question_gen_chain.invoke({\"answer\":test_answer})\n",
    "\n",
    "print(\"üîç STEP 1: Generated Hypothetical Questions\")\n",
    "print(\"=\" * 50)\n",
    "print(generated_question)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "546ef65c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìã Questions for embedding comparison:\n",
      "   Original:  When was the first Super Bowl?\n",
      "   Generated:\n",
      "      1. When was the first Super Bowl held?\n",
      "      2. What date was the inaugural Super Bowl?\n",
      "      3. On what day did the first Super Bowl take place?\n"
     ]
    }
   ],
   "source": [
    "generated_questions = [\n",
    "    \"When was the first Super Bowl held?\",\n",
    "    \"What date was the inaugural Super Bowl?\",\n",
    "    \"On what day did the first Super Bowl take place?\"\n",
    "]\n",
    "\n",
    "print(\"üìã Questions for embedding comparison:\")\n",
    "print(\"   Original: \",original_question)\n",
    "print(\"   Generated:\")\n",
    "for i,q in enumerate(generated_questions,1):\n",
    "    print(f\"      {i}. {q}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "f5324863",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Cosine similarity function ready\n",
      "\n",
      "üìê Formula: cos(Œ∏) = (A ¬∑ B) / (||A|| √ó ||B||)\n"
     ]
    }
   ],
   "source": [
    "def cosine_similarity(vec1, vec2):\n",
    "    vec1 = np.array(vec1)\n",
    "    vec2 = np.array(vec2)\n",
    "    return np.dot(vec1, vec2) / (np.linalg.norm(vec1) * np.linalg.norm(vec2))\n",
    "\n",
    "print(\"‚úÖ Cosine similarity function ready\")\n",
    "print(\"\\nüìê Formula: cos(Œ∏) = (A ¬∑ B) / (||A|| √ó ||B||)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "76256cb7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîç STEP : Computing Embeddings and Similarities\n",
      "============================================================\n",
      "\n",
      "‚úÖ Original question embedded (dim=1536)\n",
      "\n",
      "   Question 1. 'When was the first Super Bowl held?'\n",
      "     Similarity to original: 0.9821\n",
      "\n",
      "   Question 2. 'What date was the inaugural Super Bowl?'\n",
      "     Similarity to original: 0.9415\n",
      "\n",
      "   Question 3. 'On what day did the first Super Bowl take place?'\n",
      "     Similarity to original: 0.9574\n"
     ]
    }
   ],
   "source": [
    "print(\"üîç STEP : Computing Embeddings and Similarities\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "original_embedding = embeddings.embed_query(original_question)\n",
    "print(f\"\\n‚úÖ Original question embedded (dim={len(original_embedding)})\")\n",
    "\n",
    "similarities = []\n",
    "for i, gen_q in enumerate(generated_questions,1):\n",
    "    gen_embedding = embeddings.embed_query(gen_q)\n",
    "    sim = cosine_similarity(original_embedding, gen_embedding)\n",
    "    similarities.append(sim)\n",
    "\n",
    "    print(f\"\\n   Question {i}. '{gen_q}'\")\n",
    "    print(f\"     Similarity to original: {sim:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "9fbc12ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üî¢ STEP 3: Calculate Answer Relevancy Score\n",
      "==================================================\n",
      "   Similarities: ['0.9821', '0.9415', '0.9574']\n",
      "   Formula: Average of similarities\n",
      "\n",
      "  (0.9821+0.9415+0.9574)/3\n",
      "\n",
      "   üìä Manual Answer Relevancy: 0.9604\n"
     ]
    }
   ],
   "source": [
    "manual_relavancy = np.mean(similarities)\n",
    "print(\"üî¢ STEP 3: Calculate Answer Relevancy Score\")\n",
    "print(\"=\" * 50)\n",
    "print(f\"   Similarities: {[f'{s:.4f}'for s in similarities]}\")\n",
    "\n",
    "print(f\"   Formula: Average of similarities\")\n",
    "print(f\"\\n  ({'+'.join([f'{s:.4f}' for s in similarities])})/{len(similarities)}\")\n",
    "print(f\"\\n   üìä Manual Answer Relevancy: {manual_relavancy:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50ccd75a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üî¨ RAGAS Answer Relevancy Result\n",
      "==================================================\n",
      "\n",
      "   Manual calculation: 0.9604\n",
      "     Ragas metric score: 0.9821\n"
     ]
    }
   ],
   "source": [
    "relevancy_sample = SingleTurnSample(\n",
    "    user_input=original_question,\n",
    "    response=test_answer,\n",
    "    retrieved_contexts=[\"The First AFL-NFL World Championship Game was played on January 15, 1967.\"]\n",
    ")\n",
    "\n",
    "relevancy_metric = ResponseRelevancy(llm=ragas_llm, embeddings=ragas_embeddings)\n",
    "ragas_relevancy = run_async(relevancy_metric.single_turn_ascore(relevancy_sample))\n",
    "\n",
    "print(\"üî¨ RAGAS Answer Relevancy Result\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "print(f\" \\n    Manual calculation: {manual_relavancy:.4f}\")\n",
    "print(f\"     Ragas metric score: {ragas_relevancy:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "08b4e5b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer Relevancy Comparison: \n",
      "======================================================================\n",
      "\n",
      "   Highly Relevant (Directly answers WHEN)\n",
      "   Q: 'When was the first Super Bowl?'\n",
      "   A: 'The first Super Bowl was held on January 15, 1967.'\n",
      "   Score: 0.9821\n",
      "\n",
      "   Partially Relevant (Answers but adds extra info)\n",
      "   Q: 'When was the first Super Bowl?'\n",
      "   A: 'The Super Bowl is the annual championship game of the NFL, f...'\n",
      "   Score: 0.9455\n",
      "\n",
      "   Low Relevancy (Doesn't answer WHEN)\n",
      "   Q: 'When was the first Super Bowl?'\n",
      "   A: 'The Super Bowl is the annual championship game of the Nation...'\n",
      "   Score: 0.8970\n",
      "\n",
      "   Off-topic (Completely irrelevant)\n",
      "   Q: 'When was the first Super Bowl?'\n",
      "   A: 'Pizza is a popular Italian dish that spread worldwide in the...'\n",
      "   Score: 0.7797\n"
     ]
    }
   ],
   "source": [
    "relevancy_examples = [\n",
    "    {\n",
    "        \"name\": \"Highly Relevant (Directly answers WHEN)\",\n",
    "        \"question\": \"When was the first Super Bowl?\",\n",
    "        \"answer\": \"The first Super Bowl was held on January 15, 1967.\",\n",
    "    },\n",
    "    {\n",
    "        \"name\": \"Partially Relevant (Answers but adds extra info)\",\n",
    "        \"question\": \"When was the first Super Bowl?\",\n",
    "        \"answer\": \"The Super Bowl is the annual championship game of the NFL, first held on January 15, 1967.\",\n",
    "    },\n",
    "    {\n",
    "        \"name\": \"Low Relevancy (Doesn't answer WHEN)\",\n",
    "        \"question\": \"When was the first Super Bowl?\",\n",
    "        \"answer\": \"The Super Bowl is the annual championship game of the National Football League.\",\n",
    "    },\n",
    "    {\n",
    "        \"name\": \"Off-topic (Completely irrelevant)\",\n",
    "        \"question\": \"When was the first Super Bowl?\",\n",
    "        \"answer\": \"Pizza is a popular Italian dish that spread worldwide in the 20th century.\",\n",
    "    }\n",
    "]\n",
    "\n",
    "print(\"Answer Relevancy Comparison: \")\n",
    "print(\"=\"*70)\n",
    "\n",
    "for example in relevancy_examples:\n",
    "    sample = SingleTurnSample(\n",
    "        user_input=example['question'],\n",
    "        response=example['answer'],\n",
    "        retrieved_contexts=[\"Context not relevant for this metric.\"]\n",
    "    )\n",
    "    score = run_async(relevancy_metric.single_turn_ascore(sample))\n",
    "\n",
    "    print(f\"\\n   {example['name']}\")\n",
    "    print(f\"   Q: '{example['question']}'\")\n",
    "    print(f\"   A: '{example['answer'][:60]}...'\"  if len(example['answer'])>60 else f\"   A: '{example['answer']}'\")\n",
    "\n",
    "    print(f\"   Score: {score:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ecf6f7e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
