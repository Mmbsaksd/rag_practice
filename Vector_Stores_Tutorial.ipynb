{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fe308cb5",
   "metadata": {},
   "source": [
    "## **Vector Stores Tutorial: Qdrant & Weaviate**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f86c029d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "f:\\sourab\\rag_practice\\.venv\\Scripts\\python.exe: No module named uv\n"
     ]
    }
   ],
   "source": [
    "!uv pip install langchain-qdrant qdrant-client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cd05cf7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "f:\\sourab\\rag_practice\\.venv\\Scripts\\python.exe: No module named uv\n"
     ]
    }
   ],
   "source": [
    "!uv pip install langchain_qdrant"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "736f83f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "f:\\sourab\\rag_practice\\.venv\\Scripts\\python.exe: No module named uv\n"
     ]
    }
   ],
   "source": [
    "!uv pip install langchain-weaviate weaviate-client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "944f1e3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#pip install langchain-ollama\n",
    "#pip install langchain-core"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "33e93508",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ“ All imports loaded correctly!\n",
      "âœ“ Using langchain_core.documents.Document (correct LangChain 1.0+ import)\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "\n",
    "from langchain_core.documents import Document\n",
    "from langchain_openai import AzureOpenAIEmbeddings\n",
    "\n",
    "from langchain_qdrant import QdrantVectorStore\n",
    "from qdrant_client import QdrantClient\n",
    "from qdrant_client.models import VectorParams, Filter, FieldCondition, MatchValue, Distance\n",
    "\n",
    "print(\"âœ“ All imports loaded correctly!\")\n",
    "print(\"âœ“ Using langchain_core.documents.Document (correct LangChain 1.0+ import)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "87aaaa31",
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings = AzureOpenAIEmbeddings(\n",
    "    azure_endpoint=os.getenv(\"AZURE_OPENAI_ENDPOINT\"),\n",
    "    api_key=os.getenv(\"AZURE_OPENAI_API_KEY\"),\n",
    "    api_version=os.getenv(\"AZURE_OPENAI_API_VERSION\"),\n",
    "    model=os.getenv(\"AZURE_OPENAI_EMBEDDING_DEPLOYMENT_NAME\")\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "93fe9c99",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ“ Created 3 sample documents:\n",
      "  1. RAG combines retrieval and generation\n",
      "     Metadata: {'topic': 'rag', 'difficulty': 'intermediate'}\n",
      "  2. LangChain simplifies LLM applications\n",
      "     Metadata: {'topic': 'langchain', 'difficulty': 'beginner'}\n",
      "  3. Vector databases enable semantic search\n",
      "     Metadata: {'topic': 'vectordb', 'difficulty': 'intermediate'}\n"
     ]
    }
   ],
   "source": [
    "sample_docs = [\n",
    "    Document(\n",
    "        page_content=\"RAG combines retrieval and generation\",\n",
    "        metadata={\"topic\": \"rag\", \"difficulty\": \"intermediate\"}\n",
    "    ),\n",
    "    Document(\n",
    "        page_content=\"LangChain simplifies LLM applications\",\n",
    "        metadata={\"topic\": \"langchain\", \"difficulty\": \"beginner\"}\n",
    "    ),\n",
    "    Document(\n",
    "        page_content=\"Vector databases enable semantic search\",\n",
    "        metadata={\"topic\": \"vectordb\", \"difficulty\": \"intermediate\"}\n",
    "    )\n",
    "]\n",
    "\n",
    "print(\"âœ“ Created 3 sample documents:\")\n",
    "for i, doc in enumerate(sample_docs, 1):\n",
    "    print(f\"  {i}. {doc.page_content}\")\n",
    "    print(f\"     Metadata: {doc.metadata}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e1e07da",
   "metadata": {},
   "source": [
    "### **Part 1: Qdrant Vector Store**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5d0709a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "QDRANT IN-MEMORY EXAMPLE\n",
      "================================================================================\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\bsmun\\AppData\\Local\\Temp\\ipykernel_17792\\2452358527.py:7: DeprecationWarning: `recreate_collection` method is deprecated and will be removed in the future. Use `collection_exists` to check collection existence and `create_collection` instead.\n",
      "  qdrant_client_memory.recreate_collection(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ“ Added documents to Qdrant (in-memory)\n",
      "  Collection: my_collection_memory\n",
      "  Documents: 3\n",
      "  Storage: RAM (temporary)\n"
     ]
    }
   ],
   "source": [
    "print(\"=\" * 80)\n",
    "print(\"QDRANT IN-MEMORY EXAMPLE\")\n",
    "print(\"=\" * 80)\n",
    "print()\n",
    "\n",
    "qdrant_client_memory = QdrantClient(location=\":memory:\")\n",
    "qdrant_client_memory.recreate_collection(\n",
    "    collection_name=\"my_collection_memory\",\n",
    "    vectors_config=VectorParams(\n",
    "        size=1536,\n",
    "        distance=Distance.COSINE,\n",
    "    )\n",
    ")\n",
    "\n",
    "qdrant_store_memory = QdrantVectorStore(\n",
    "    client=qdrant_client_memory,\n",
    "    collection_name=\"my_collection_memory\",\n",
    "    embedding=embeddings\n",
    ")\n",
    "\n",
    "qdrant_store_memory.add_documents(sample_docs)\n",
    "\n",
    "print(\"âœ“ Added documents to Qdrant (in-memory)\")\n",
    "print(\"  Collection: my_collection_memory\")\n",
    "print(\"  Documents: 3\")\n",
    "print(\"  Storage: RAM (temporary)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "208a4ed0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--------------------------------------------------------------------------------\n",
      "BASIC SIMILARITY SEARCH\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "Query: 'Tell me about RAG'\n",
      "\n",
      "Search results:\n",
      "  1. RAG combines retrieval and generation\n",
      "     Metadata: {'topic': 'rag', 'difficulty': 'intermediate', '_id': '16587108236b4a4699e52a59a80a676d', '_collection_name': 'my_collection_memory'}\n",
      "  2. Vector databases enable semantic search\n",
      "     Metadata: {'topic': 'vectordb', 'difficulty': 'intermediate', '_id': '3d90f26af8814bf190cbb8d66f598c1e', '_collection_name': 'my_collection_memory'}\n",
      "\n",
      "ðŸ’¡ Notice: The document about 'RAG combines retrieval...' is returned first\n",
      "   because it's semantically most similar to our query!\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n\" + \"-\" * 80)\n",
    "print(\"BASIC SIMILARITY SEARCH\")\n",
    "print(\"-\" * 80)\n",
    "\n",
    "results = qdrant_store_memory.similarity_search(\n",
    "    \"Tell me about Rag\",\n",
    "    k=2\n",
    ")\n",
    "\n",
    "print(\"\\nQuery: 'Tell me about RAG'\")\n",
    "print(\"\\nSearch results:\")\n",
    "for i, doc in enumerate(results, 1):\n",
    "    print(f\"  {i}. {doc.page_content}\")\n",
    "    print(f\"     Metadata: {doc.metadata}\")\n",
    "\n",
    "print(\"\\nðŸ’¡ Notice: The document about 'RAG combines retrieval...' is returned first\")\n",
    "print(\"   because it's semantically most similar to our query!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2829d94f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--------------------------------------------------------------------------------\n",
      "SEARCH WITH METADATA FILTER\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "Query: 'Tell me about RAG'\n",
      "Filter: topic='rag'\n",
      "\n",
      "Filtered search results:\n",
      "  1. RAG combines retrieval and generation\n",
      "     Metadata: {'topic': 'rag', 'difficulty': 'intermediate', '_id': '16587108236b4a4699e52a59a80a676d', '_collection_name': 'my_collection_memory'}\n",
      "\n",
      "ðŸ’¡ Only documents with topic='rag' are returned!\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n\" + \"-\" * 80)\n",
    "print(\"SEARCH WITH METADATA FILTER\")\n",
    "print(\"-\" * 80)\n",
    "\n",
    "qdrant_filter = Filter(\n",
    "    must=[\n",
    "        FieldCondition(\n",
    "            key=\"metadata.topic\",\n",
    "            match=MatchValue(value=\"rag\")\n",
    "        )\n",
    "    ]\n",
    ")\n",
    "results_filtered = qdrant_store_memory.similarity_search(\n",
    "    \"Tell me about RAG\",\n",
    "    k=2,\n",
    "    filter=qdrant_filter\n",
    ")\n",
    "\n",
    "print(\"\\nQuery: 'Tell me about RAG'\")\n",
    "print(\"Filter: topic='rag'\")\n",
    "print(\"\\nFiltered search results:\")\n",
    "for i, doc in enumerate(results_filtered, 1):\n",
    "    print(f\"  {i}. {doc.page_content}\")\n",
    "    print(f\"     Metadata: {doc.metadata}\")\n",
    "\n",
    "print(\"\\nðŸ’¡ Only documents with topic='rag' are returned!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "15d3248a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--------------------------------------------------------------------------------\n",
      "SEARCH WITH METADATA FILTER\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "Query: 'Tell me about RAG'\n",
      "Filter: topic='rag'\n",
      "\n",
      "Filtered search results:\n",
      "  1. RAG combines retrieval and generation\n",
      "     Metadata: {'topic': 'rag', 'difficulty': 'intermediate', '_id': '16587108236b4a4699e52a59a80a676d', '_collection_name': 'my_collection_memory'}\n",
      "\n",
      "ðŸ’¡ Only documents with topic='rag' are returned!\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n\" + \"-\" * 80)\n",
    "print(\"SEARCH WITH METADATA FILTER\")\n",
    "print(\"-\" * 80)\n",
    "\n",
    "qdrant_filter = Filter(\n",
    "    must=[\n",
    "        FieldCondition(\n",
    "            key=\"metadata.topic\",\n",
    "            match=MatchValue(value=\"rag\")\n",
    "        )\n",
    "    ]\n",
    ")\n",
    "results_filtered = qdrant_store_memory.similarity_search(\n",
    "    \"Tell me about RAG\",\n",
    "    k=2,\n",
    "    filter=qdrant_filter\n",
    ")\n",
    "\n",
    "print(\"\\nQuery: 'Tell me about RAG'\")\n",
    "print(\"Filter: topic='rag'\")\n",
    "print(\"\\nFiltered search results:\")\n",
    "for i, doc in enumerate(results_filtered, 1):\n",
    "    print(f\"  {i}. {doc.page_content}\")\n",
    "    print(f\"     Metadata: {doc.metadata}\")\n",
    "\n",
    "print(\"\\nðŸ’¡ Only documents with topic='rag' are returned!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f03e792",
   "metadata": {},
   "source": [
    "### **Multiple Filter Conditions (AND Logic)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "35b60192",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Query: 'Tell me about RAG'\n",
      "Filter: topic='rag'\n",
      "\n",
      "Filtered search results:\n",
      "\n",
      "ðŸ’¡ Only documents with topic='rag' are returned!\n"
     ]
    }
   ],
   "source": [
    "multi_filter = Filter(\n",
    "    must=[\n",
    "        FieldCondition(\n",
    "            key=\"metadata.topic\",\n",
    "            match=MatchValue(value='rag')\n",
    "        ),\n",
    "        FieldCondition(\n",
    "            key='metadata.topic',\n",
    "            match=MatchValue(value=\"intermediate\")\n",
    "        )\n",
    "    ]\n",
    ")\n",
    "\n",
    "results_filtered = qdrant_store_memory.similarity_search(\n",
    "    \"Tell me about RAG\",\n",
    "    k=2,\n",
    "    filter=multi_filter\n",
    ")\n",
    "\n",
    "print(\"\\nQuery: 'Tell me about RAG'\")\n",
    "print(\"Filter: topic='rag'\")\n",
    "print(\"\\nFiltered search results:\")\n",
    "for i, doc in enumerate(results_filtered, 1):\n",
    "    print(f\"  {i}. {doc.page_content}\")\n",
    "    print(f\"     Metadata: {doc.metadata}\")\n",
    "\n",
    "print(\"\\nðŸ’¡ Only documents with topic='rag' are returned!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f5c86b9",
   "metadata": {},
   "source": [
    "### **Qdrant with Local Persistence**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "7c4669ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "QDRANT WITH LOCAL PERSISTENCE\n",
      "================================================================================\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\bsmun\\AppData\\Local\\Temp\\ipykernel_17792\\1976516880.py:8: DeprecationWarning: `recreate_collection` method is deprecated and will be removed in the future. Use `collection_exists` to check collection existence and `create_collection` instead.\n",
      "  qdrant_client_persistent.recreate_collection(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ“ Added documents to Qdrant (persistent)\n",
      "  Storage location: ./qdrant_data\n",
      "  Collection: my_collection_persistent\n",
      "  âš ï¸  Data will persist even after this script ends!\n",
      "\n",
      "Query: 'Tell me about LangChain'\n",
      "\n",
      "Search results:\n",
      "  1. LangChain simplifies LLM applications\n",
      "     Metadata: {'topic': 'langchain', 'difficulty': 'beginner', '_id': 'a97d815f6f3d4979a26fd17e1f43f6dc', '_collection_name': 'my_collection_persistent'}\n",
      "  2. Vector databases enable semantic search\n",
      "     Metadata: {'topic': 'vectordb', 'difficulty': 'intermediate', '_id': '839a989af29d4468b6fc1f218b8b2abf', '_collection_name': 'my_collection_persistent'}\n",
      "\n",
      "ðŸ’¡ Next time you run this, you can load the same data from disk!\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"QDRANT WITH LOCAL PERSISTENCE\")\n",
    "print(\"=\" * 80)\n",
    "print()\n",
    "\n",
    "qdrant_path = \"./qdrant_data\"\n",
    "qdrant_client_persistent = QdrantClient(path=qdrant_path)\n",
    "qdrant_client_persistent.recreate_collection(\n",
    "    collection_name=\"my_collection_persistent\",\n",
    "    vectors_config=VectorParams(\n",
    "        size=1536,\n",
    "        distance=Distance.COSINE\n",
    "    ),\n",
    ")\n",
    "qdrant_store_persistent = QdrantVectorStore(\n",
    "    client=qdrant_client_persistent,\n",
    "    collection_name=\"my_collection_persistent\",\n",
    "    embedding=embeddings\n",
    ")\n",
    "\n",
    "qdrant_store_persistent.add_documents(sample_docs)\n",
    "print(f\"âœ“ Added documents to Qdrant (persistent)\")\n",
    "print(f\"  Storage location: {qdrant_path}\")\n",
    "print(f\"  Collection: my_collection_persistent\")\n",
    "print(f\"  âš ï¸  Data will persist even after this script ends!\")\n",
    "\n",
    "results = qdrant_store_persistent.similarity_search(\n",
    "    \"Tell me about Langchain\",\n",
    "    k=2\n",
    ")\n",
    "\n",
    "\n",
    "print(\"\\nQuery: 'Tell me about LangChain'\")\n",
    "print(\"\\nSearch results:\")\n",
    "for i, doc in enumerate(results, 1):\n",
    "    print(f\"  {i}. {doc.page_content}\")\n",
    "    print(f\"     Metadata: {doc.metadata}\")\n",
    "\n",
    "print(\"\\nðŸ’¡ Next time you run this, you can load the same data from disk!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0abed224",
   "metadata": {},
   "source": [
    "###  **Qdrant from_documents**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "7e9e7a5e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "QDRANT FROM_DOCUMENTS (RECOMMENDED METHOD)\n",
      "================================================================================\n",
      "\n",
      "âœ“ Created Qdrant store from documents\n",
      "  Collection: rag_collection\n",
      "  Storage: ./qdrant_easy\n",
      "  Documents: 3\n",
      "\n",
      "ðŸ’¡ This is the recommended approach for most use cases!\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"QDRANT FROM_DOCUMENTS (RECOMMENDED METHOD)\")\n",
    "print(\"=\" * 80)\n",
    "print()\n",
    "\n",
    "qdrant_store_easy = QdrantVectorStore.from_documents(\n",
    "    documents=sample_docs,\n",
    "    embedding=embeddings,\n",
    "    path=\"./qdrant_easy\",\n",
    "    collection_name=\"rag_collection\"\n",
    ")\n",
    "\n",
    "print(\"âœ“ Created Qdrant store from documents\")\n",
    "print(\"  Collection: rag_collection\")\n",
    "print(\"  Storage: ./qdrant_easy\")\n",
    "print(\"  Documents: 3\")\n",
    "print(\"\\nðŸ’¡ This is the recommended approach for most use cases!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "1732e32e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(Document(metadata={'topic': 'vectordb', 'difficulty': 'intermediate', '_id': '0f622ce5abfb4f15ae7be2026662a006', '_collection_name': 'rag_collection'}, page_content='Vector databases enable semantic search'), 0.90523565515644), (Document(metadata={'topic': 'langchain', 'difficulty': 'beginner', '_id': '2f373810db264aa28480bd52e9f50f48', '_collection_name': 'rag_collection'}, page_content='LangChain simplifies LLM applications'), 0.7368039651195374), (Document(metadata={'topic': 'rag', 'difficulty': 'intermediate', '_id': 'bf119b1b2a7944a2925f6b8d0b36e1ee', '_collection_name': 'rag_collection'}, page_content='RAG combines retrieval and generation'), 0.7327351479175784)]\n",
      "\n",
      "Query: 'Vector databases'\n",
      "\n",
      "Search results with similarity scores:\n",
      "\n",
      "  Score: 0.9052\n",
      "  Content: Vector databases enable semantic search\n",
      "  Metadata: {'topic': 'vectordb', 'difficulty': 'intermediate', '_id': '0f622ce5abfb4f15ae7be2026662a006', '_collection_name': 'rag_collection'}\n",
      "\n",
      "  Score: 0.7368\n",
      "  Content: LangChain simplifies LLM applications\n",
      "  Metadata: {'topic': 'langchain', 'difficulty': 'beginner', '_id': '2f373810db264aa28480bd52e9f50f48', '_collection_name': 'rag_collection'}\n",
      "\n",
      "  Score: 0.7327\n",
      "  Content: RAG combines retrieval and generation\n",
      "  Metadata: {'topic': 'rag', 'difficulty': 'intermediate', '_id': 'bf119b1b2a7944a2925f6b8d0b36e1ee', '_collection_name': 'rag_collection'}\n",
      "\n",
      "ðŸ’¡ Scores help you filter out low-quality results\n",
      "ðŸ’¡ You can set a threshold (e.g., only return results with score > 0.7)\n"
     ]
    }
   ],
   "source": [
    "result_with_scores = qdrant_store_easy.similarity_search_with_score(\n",
    "    \"Vector database\",\n",
    "    k=3\n",
    ")\n",
    "print(result_with_scores)\n",
    "\n",
    "print(\"\\nQuery: 'Vector databases'\")\n",
    "print(\"\\nSearch results with similarity scores:\")\n",
    "print()\n",
    "for doc, score in result_with_scores:\n",
    "    print(f\"  Score: {score:.4f}\")  # Similarity score (higher = more similar)\n",
    "    print(f\"  Content: {doc.page_content}\")\n",
    "    print(f\"  Metadata: {doc.metadata}\")\n",
    "    print()\n",
    "\n",
    "print(\"ðŸ’¡ Scores help you filter out low-quality results\")\n",
    "print(\"ðŸ’¡ You can set a threshold (e.g., only return results with score > 0.7)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc6f7de5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
