{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fe308cb5",
   "metadata": {},
   "source": [
    "## **Vector Stores Tutorial: Qdrant & Weaviate**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f86c029d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "f:\\sourab\\rag_practice\\.venv\\Scripts\\python.exe: No module named uv\n"
     ]
    }
   ],
   "source": [
    "!uv pip install langchain-qdrant qdrant-client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cd05cf7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "f:\\sourab\\rag_practice\\.venv\\Scripts\\python.exe: No module named uv\n"
     ]
    }
   ],
   "source": [
    "!uv pip install langchain_qdrant"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "736f83f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "f:\\sourab\\rag_practice\\.venv\\Scripts\\python.exe: No module named uv\n"
     ]
    }
   ],
   "source": [
    "!uv pip install langchain-weaviate weaviate-client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "944f1e3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#pip install langchain-ollama\n",
    "#pip install langchain-core"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "33e93508",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úì All imports loaded correctly!\n",
      "‚úì Using langchain_core.documents.Document (correct LangChain 1.0+ import)\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "\n",
    "from langchain_core.documents import Document\n",
    "from langchain_openai import AzureOpenAIEmbeddings\n",
    "\n",
    "from langchain_qdrant import QdrantVectorStore\n",
    "from qdrant_client import QdrantClient\n",
    "from qdrant_client.models import VectorParams, Filter, FieldCondition, MatchValue, Distance\n",
    "\n",
    "print(\"‚úì All imports loaded correctly!\")\n",
    "print(\"‚úì Using langchain_core.documents.Document (correct LangChain 1.0+ import)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "87aaaa31",
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings = AzureOpenAIEmbeddings(\n",
    "    azure_endpoint=os.getenv(\"AZURE_OPENAI_ENDPOINT\"),\n",
    "    api_key=os.getenv(\"AZURE_OPENAI_API_KEY\"),\n",
    "    api_version=os.getenv(\"AZURE_OPENAI_API_VERSION\"),\n",
    "    model=os.getenv(\"AZURE_OPENAI_EMBEDDING_DEPLOYMENT_NAME\")\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "93fe9c99",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úì Created 3 sample documents:\n",
      "  1. RAG combines retrieval and generation\n",
      "     Metadata: {'topic': 'rag', 'difficulty': 'intermediate'}\n",
      "  2. LangChain simplifies LLM applications\n",
      "     Metadata: {'topic': 'langchain', 'difficulty': 'beginner'}\n",
      "  3. Vector databases enable semantic search\n",
      "     Metadata: {'topic': 'vectordb', 'difficulty': 'intermediate'}\n"
     ]
    }
   ],
   "source": [
    "sample_docs = [\n",
    "    Document(\n",
    "        page_content=\"RAG combines retrieval and generation\",\n",
    "        metadata={\"topic\": \"rag\", \"difficulty\": \"intermediate\"}\n",
    "    ),\n",
    "    Document(\n",
    "        page_content=\"LangChain simplifies LLM applications\",\n",
    "        metadata={\"topic\": \"langchain\", \"difficulty\": \"beginner\"}\n",
    "    ),\n",
    "    Document(\n",
    "        page_content=\"Vector databases enable semantic search\",\n",
    "        metadata={\"topic\": \"vectordb\", \"difficulty\": \"intermediate\"}\n",
    "    )\n",
    "]\n",
    "\n",
    "print(\"‚úì Created 3 sample documents:\")\n",
    "for i, doc in enumerate(sample_docs, 1):\n",
    "    print(f\"  {i}. {doc.page_content}\")\n",
    "    print(f\"     Metadata: {doc.metadata}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e1e07da",
   "metadata": {},
   "source": [
    "### **Part 1: Qdrant Vector Store**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5d0709a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "QDRANT IN-MEMORY EXAMPLE\n",
      "================================================================================\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\bsmun\\AppData\\Local\\Temp\\ipykernel_17792\\2452358527.py:7: DeprecationWarning: `recreate_collection` method is deprecated and will be removed in the future. Use `collection_exists` to check collection existence and `create_collection` instead.\n",
      "  qdrant_client_memory.recreate_collection(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úì Added documents to Qdrant (in-memory)\n",
      "  Collection: my_collection_memory\n",
      "  Documents: 3\n",
      "  Storage: RAM (temporary)\n"
     ]
    }
   ],
   "source": [
    "print(\"=\" * 80)\n",
    "print(\"QDRANT IN-MEMORY EXAMPLE\")\n",
    "print(\"=\" * 80)\n",
    "print()\n",
    "\n",
    "qdrant_client_memory = QdrantClient(location=\":memory:\")\n",
    "qdrant_client_memory.recreate_collection(\n",
    "    collection_name=\"my_collection_memory\",\n",
    "    vectors_config=VectorParams(\n",
    "        size=1536,\n",
    "        distance=Distance.COSINE,\n",
    "    )\n",
    ")\n",
    "\n",
    "qdrant_store_memory = QdrantVectorStore(\n",
    "    client=qdrant_client_memory,\n",
    "    collection_name=\"my_collection_memory\",\n",
    "    embedding=embeddings\n",
    ")\n",
    "\n",
    "qdrant_store_memory.add_documents(sample_docs)\n",
    "\n",
    "print(\"‚úì Added documents to Qdrant (in-memory)\")\n",
    "print(\"  Collection: my_collection_memory\")\n",
    "print(\"  Documents: 3\")\n",
    "print(\"  Storage: RAM (temporary)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "208a4ed0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--------------------------------------------------------------------------------\n",
      "BASIC SIMILARITY SEARCH\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "Query: 'Tell me about RAG'\n",
      "\n",
      "Search results:\n",
      "  1. RAG combines retrieval and generation\n",
      "     Metadata: {'topic': 'rag', 'difficulty': 'intermediate', '_id': '16587108236b4a4699e52a59a80a676d', '_collection_name': 'my_collection_memory'}\n",
      "  2. Vector databases enable semantic search\n",
      "     Metadata: {'topic': 'vectordb', 'difficulty': 'intermediate', '_id': '3d90f26af8814bf190cbb8d66f598c1e', '_collection_name': 'my_collection_memory'}\n",
      "\n",
      "üí° Notice: The document about 'RAG combines retrieval...' is returned first\n",
      "   because it's semantically most similar to our query!\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n\" + \"-\" * 80)\n",
    "print(\"BASIC SIMILARITY SEARCH\")\n",
    "print(\"-\" * 80)\n",
    "\n",
    "results = qdrant_store_memory.similarity_search(\n",
    "    \"Tell me about Rag\",\n",
    "    k=2\n",
    ")\n",
    "\n",
    "print(\"\\nQuery: 'Tell me about RAG'\")\n",
    "print(\"\\nSearch results:\")\n",
    "for i, doc in enumerate(results, 1):\n",
    "    print(f\"  {i}. {doc.page_content}\")\n",
    "    print(f\"     Metadata: {doc.metadata}\")\n",
    "\n",
    "print(\"\\nüí° Notice: The document about 'RAG combines retrieval...' is returned first\")\n",
    "print(\"   because it's semantically most similar to our query!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2829d94f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--------------------------------------------------------------------------------\n",
      "SEARCH WITH METADATA FILTER\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "Query: 'Tell me about RAG'\n",
      "Filter: topic='rag'\n",
      "\n",
      "Filtered search results:\n",
      "  1. RAG combines retrieval and generation\n",
      "     Metadata: {'topic': 'rag', 'difficulty': 'intermediate', '_id': '16587108236b4a4699e52a59a80a676d', '_collection_name': 'my_collection_memory'}\n",
      "\n",
      "üí° Only documents with topic='rag' are returned!\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n\" + \"-\" * 80)\n",
    "print(\"SEARCH WITH METADATA FILTER\")\n",
    "print(\"-\" * 80)\n",
    "\n",
    "qdrant_filter = Filter(\n",
    "    must=[\n",
    "        FieldCondition(\n",
    "            key=\"metadata.topic\",\n",
    "            match=MatchValue(value=\"rag\")\n",
    "        )\n",
    "    ]\n",
    ")\n",
    "results_filtered = qdrant_store_memory.similarity_search(\n",
    "    \"Tell me about RAG\",\n",
    "    k=2,\n",
    "    filter=qdrant_filter\n",
    ")\n",
    "\n",
    "print(\"\\nQuery: 'Tell me about RAG'\")\n",
    "print(\"Filter: topic='rag'\")\n",
    "print(\"\\nFiltered search results:\")\n",
    "for i, doc in enumerate(results_filtered, 1):\n",
    "    print(f\"  {i}. {doc.page_content}\")\n",
    "    print(f\"     Metadata: {doc.metadata}\")\n",
    "\n",
    "print(\"\\nüí° Only documents with topic='rag' are returned!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "15d3248a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--------------------------------------------------------------------------------\n",
      "SEARCH WITH METADATA FILTER\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "Query: 'Tell me about RAG'\n",
      "Filter: topic='rag'\n",
      "\n",
      "Filtered search results:\n",
      "  1. RAG combines retrieval and generation\n",
      "     Metadata: {'topic': 'rag', 'difficulty': 'intermediate', '_id': '16587108236b4a4699e52a59a80a676d', '_collection_name': 'my_collection_memory'}\n",
      "\n",
      "üí° Only documents with topic='rag' are returned!\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n\" + \"-\" * 80)\n",
    "print(\"SEARCH WITH METADATA FILTER\")\n",
    "print(\"-\" * 80)\n",
    "\n",
    "qdrant_filter = Filter(\n",
    "    must=[\n",
    "        FieldCondition(\n",
    "            key=\"metadata.topic\",\n",
    "            match=MatchValue(value=\"rag\")\n",
    "        )\n",
    "    ]\n",
    ")\n",
    "results_filtered = qdrant_store_memory.similarity_search(\n",
    "    \"Tell me about RAG\",\n",
    "    k=2,\n",
    "    filter=qdrant_filter\n",
    ")\n",
    "\n",
    "print(\"\\nQuery: 'Tell me about RAG'\")\n",
    "print(\"Filter: topic='rag'\")\n",
    "print(\"\\nFiltered search results:\")\n",
    "for i, doc in enumerate(results_filtered, 1):\n",
    "    print(f\"  {i}. {doc.page_content}\")\n",
    "    print(f\"     Metadata: {doc.metadata}\")\n",
    "\n",
    "print(\"\\nüí° Only documents with topic='rag' are returned!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f03e792",
   "metadata": {},
   "source": [
    "### **Multiple Filter Conditions (AND Logic)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "35b60192",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Query: 'Tell me about RAG'\n",
      "Filter: topic='rag'\n",
      "\n",
      "Filtered search results:\n",
      "\n",
      "üí° Only documents with topic='rag' are returned!\n"
     ]
    }
   ],
   "source": [
    "multi_filter = Filter(\n",
    "    must=[\n",
    "        FieldCondition(\n",
    "            key=\"metadata.topic\",\n",
    "            match=MatchValue(value='rag')\n",
    "        ),\n",
    "        FieldCondition(\n",
    "            key='metadata.topic',\n",
    "            match=MatchValue(value=\"intermediate\")\n",
    "        )\n",
    "    ]\n",
    ")\n",
    "\n",
    "results_filtered = qdrant_store_memory.similarity_search(\n",
    "    \"Tell me about RAG\",\n",
    "    k=2,\n",
    "    filter=multi_filter\n",
    ")\n",
    "\n",
    "print(\"\\nQuery: 'Tell me about RAG'\")\n",
    "print(\"Filter: topic='rag'\")\n",
    "print(\"\\nFiltered search results:\")\n",
    "for i, doc in enumerate(results_filtered, 1):\n",
    "    print(f\"  {i}. {doc.page_content}\")\n",
    "    print(f\"     Metadata: {doc.metadata}\")\n",
    "\n",
    "print(\"\\nüí° Only documents with topic='rag' are returned!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f5c86b9",
   "metadata": {},
   "source": [
    "### **Qdrant with Local Persistence**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "7c4669ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "QDRANT WITH LOCAL PERSISTENCE\n",
      "================================================================================\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\bsmun\\AppData\\Local\\Temp\\ipykernel_17792\\1976516880.py:8: DeprecationWarning: `recreate_collection` method is deprecated and will be removed in the future. Use `collection_exists` to check collection existence and `create_collection` instead.\n",
      "  qdrant_client_persistent.recreate_collection(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úì Added documents to Qdrant (persistent)\n",
      "  Storage location: ./qdrant_data\n",
      "  Collection: my_collection_persistent\n",
      "  ‚ö†Ô∏è  Data will persist even after this script ends!\n",
      "\n",
      "Query: 'Tell me about LangChain'\n",
      "\n",
      "Search results:\n",
      "  1. LangChain simplifies LLM applications\n",
      "     Metadata: {'topic': 'langchain', 'difficulty': 'beginner', '_id': 'a97d815f6f3d4979a26fd17e1f43f6dc', '_collection_name': 'my_collection_persistent'}\n",
      "  2. Vector databases enable semantic search\n",
      "     Metadata: {'topic': 'vectordb', 'difficulty': 'intermediate', '_id': '839a989af29d4468b6fc1f218b8b2abf', '_collection_name': 'my_collection_persistent'}\n",
      "\n",
      "üí° Next time you run this, you can load the same data from disk!\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"QDRANT WITH LOCAL PERSISTENCE\")\n",
    "print(\"=\" * 80)\n",
    "print()\n",
    "\n",
    "qdrant_path = \"./qdrant_data\"\n",
    "qdrant_client_persistent = QdrantClient(path=qdrant_path)\n",
    "qdrant_client_persistent.recreate_collection(\n",
    "    collection_name=\"my_collection_persistent\",\n",
    "    vectors_config=VectorParams(\n",
    "        size=1536,\n",
    "        distance=Distance.COSINE\n",
    "    ),\n",
    ")\n",
    "qdrant_store_persistent = QdrantVectorStore(\n",
    "    client=qdrant_client_persistent,\n",
    "    collection_name=\"my_collection_persistent\",\n",
    "    embedding=embeddings\n",
    ")\n",
    "\n",
    "qdrant_store_persistent.add_documents(sample_docs)\n",
    "print(f\"‚úì Added documents to Qdrant (persistent)\")\n",
    "print(f\"  Storage location: {qdrant_path}\")\n",
    "print(f\"  Collection: my_collection_persistent\")\n",
    "print(f\"  ‚ö†Ô∏è  Data will persist even after this script ends!\")\n",
    "\n",
    "results = qdrant_store_persistent.similarity_search(\n",
    "    \"Tell me about Langchain\",\n",
    "    k=2\n",
    ")\n",
    "\n",
    "\n",
    "print(\"\\nQuery: 'Tell me about LangChain'\")\n",
    "print(\"\\nSearch results:\")\n",
    "for i, doc in enumerate(results, 1):\n",
    "    print(f\"  {i}. {doc.page_content}\")\n",
    "    print(f\"     Metadata: {doc.metadata}\")\n",
    "\n",
    "print(\"\\nüí° Next time you run this, you can load the same data from disk!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0abed224",
   "metadata": {},
   "source": [
    "###  **Qdrant from_documents**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "7e9e7a5e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "QDRANT FROM_DOCUMENTS (RECOMMENDED METHOD)\n",
      "================================================================================\n",
      "\n",
      "‚úì Created Qdrant store from documents\n",
      "  Collection: rag_collection\n",
      "  Storage: ./qdrant_easy\n",
      "  Documents: 3\n",
      "\n",
      "üí° This is the recommended approach for most use cases!\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"QDRANT FROM_DOCUMENTS (RECOMMENDED METHOD)\")\n",
    "print(\"=\" * 80)\n",
    "print()\n",
    "\n",
    "qdrant_store_easy = QdrantVectorStore.from_documents(\n",
    "    documents=sample_docs,\n",
    "    embedding=embeddings,\n",
    "    path=\"./qdrant_easy\",\n",
    "    collection_name=\"rag_collection\"\n",
    ")\n",
    "\n",
    "print(\"‚úì Created Qdrant store from documents\")\n",
    "print(\"  Collection: rag_collection\")\n",
    "print(\"  Storage: ./qdrant_easy\")\n",
    "print(\"  Documents: 3\")\n",
    "print(\"\\nüí° This is the recommended approach for most use cases!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "1732e32e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(Document(metadata={'topic': 'vectordb', 'difficulty': 'intermediate', '_id': '0f622ce5abfb4f15ae7be2026662a006', '_collection_name': 'rag_collection'}, page_content='Vector databases enable semantic search'), 0.90523565515644), (Document(metadata={'topic': 'langchain', 'difficulty': 'beginner', '_id': '2f373810db264aa28480bd52e9f50f48', '_collection_name': 'rag_collection'}, page_content='LangChain simplifies LLM applications'), 0.7368039651195374), (Document(metadata={'topic': 'rag', 'difficulty': 'intermediate', '_id': 'bf119b1b2a7944a2925f6b8d0b36e1ee', '_collection_name': 'rag_collection'}, page_content='RAG combines retrieval and generation'), 0.7327351479175784)]\n",
      "\n",
      "Query: 'Vector databases'\n",
      "\n",
      "Search results with similarity scores:\n",
      "\n",
      "  Score: 0.9052\n",
      "  Content: Vector databases enable semantic search\n",
      "  Metadata: {'topic': 'vectordb', 'difficulty': 'intermediate', '_id': '0f622ce5abfb4f15ae7be2026662a006', '_collection_name': 'rag_collection'}\n",
      "\n",
      "  Score: 0.7368\n",
      "  Content: LangChain simplifies LLM applications\n",
      "  Metadata: {'topic': 'langchain', 'difficulty': 'beginner', '_id': '2f373810db264aa28480bd52e9f50f48', '_collection_name': 'rag_collection'}\n",
      "\n",
      "  Score: 0.7327\n",
      "  Content: RAG combines retrieval and generation\n",
      "  Metadata: {'topic': 'rag', 'difficulty': 'intermediate', '_id': 'bf119b1b2a7944a2925f6b8d0b36e1ee', '_collection_name': 'rag_collection'}\n",
      "\n",
      "üí° Scores help you filter out low-quality results\n",
      "üí° You can set a threshold (e.g., only return results with score > 0.7)\n"
     ]
    }
   ],
   "source": [
    "result_with_scores = qdrant_store_easy.similarity_search_with_score(\n",
    "    \"Vector database\",\n",
    "    k=3\n",
    ")\n",
    "print(result_with_scores)\n",
    "\n",
    "print(\"\\nQuery: 'Vector databases'\")\n",
    "print(\"\\nSearch results with similarity scores:\")\n",
    "print()\n",
    "for doc, score in result_with_scores:\n",
    "    print(f\"  Score: {score:.4f}\")  # Similarity score (higher = more similar)\n",
    "    print(f\"  Content: {doc.page_content}\")\n",
    "    print(f\"  Metadata: {doc.metadata}\")\n",
    "    print()\n",
    "\n",
    "print(\"üí° Scores help you filter out low-quality results\")\n",
    "print(\"üí° You can set a threshold (e.g., only return results with score > 0.7)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c39c27cb",
   "metadata": {},
   "source": [
    "## **Part 2: Weaviate Vector Store**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ed808831",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "WEAVIATE LOCAL VECTOR STORE EXAMPLE\n",
      "================================================================================\n",
      "\n",
      "‚ö†Ô∏è  Note: This requires Weaviate running locally on port 8080\n",
      "   If not running, you'll see connection errors (that's OK for learning!)\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "Connecting to Local Weaviate\n",
      "--------------------------------------------------------------------------------\n",
      "‚úì Connected to local Weaviate\n",
      "  Host: localhost:8080\n",
      "  gRPC Port: 50051\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "Creating Weaviate Vector Store\n",
      "--------------------------------------------------------------------------------\n",
      "‚úì Added documents to Weaviate\n",
      "  Index: MyDocuments\n",
      "  Documents: 3\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "Basic Search\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "Query: Tell me about RAG\n",
      "\n",
      "Search results: \n",
      "1. RAG combines retrieval and generation\n",
      "   Metadata: {'difficulty': 'intermediate', 'topic': 'rag'}\n",
      "2. RAG combines retrieval and generation\n",
      "   Metadata: {'difficulty': 'intermediate', 'topic': 'rag'}\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "Search with Metadata Filter\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "Query: 'Tell me about databases'\n",
      "Filter: difficulty='intermediate'\n",
      "\n",
      "Filtered search results:\n",
      "1. Vector databases enable semantic search\n",
      "    Metadata: {'difficulty': 'intermediate', 'topic': 'vectordb'}\n",
      "2. Vector databases enable semantic search\n",
      "    Metadata: {'difficulty': 'intermediate', 'topic': 'vectordb'}\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "Search with Scores\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "Query: 'Vector databases'\n",
      "\n",
      "Search results with scores:\n",
      "   Score: 1.0000\n",
      "   Content: Vector databases enable semantic search\n",
      "   Metadata: {'difficulty': 'intermediate', 'topic': 'vectordb'}\n",
      "   Score: 0.9994\n",
      "   Content: Vector databases enable semantic search\n",
      "   Metadata: {'difficulty': 'intermediate', 'topic': 'vectordb'}\n",
      "--------------------------------------------------------------------------------\n",
      "Creating Weaviate from Documents (Alternative Method)\n",
      "--------------------------------------------------------------------------------\n",
      "‚úì Created Weaviate store from documents\n",
      "\n",
      "Quick search results:\n",
      "  1. LangChain simplifies LLM applications\n",
      "  2. LangChain simplifies LLM applications\n",
      "\n",
      "‚úì Closed Weaviate connection\n"
     ]
    }
   ],
   "source": [
    "from weaviate.classes.query import Filter\n",
    "\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"WEAVIATE LOCAL VECTOR STORE EXAMPLE\")\n",
    "print(\"=\" * 80)\n",
    "print()\n",
    "print(\"‚ö†Ô∏è  Note: This requires Weaviate running locally on port 8080\")\n",
    "print(\"   If not running, you'll see connection errors (that's OK for learning!)\")\n",
    "print()\n",
    "\n",
    "try:\n",
    "    import weaviate\n",
    "    from langchain_weaviate import WeaviateVectorStore\n",
    "\n",
    "    print(\"-\" * 80)\n",
    "    print(\"Connecting to Local Weaviate\")\n",
    "    print(\"-\" * 80)\n",
    "\n",
    "    # Step 1: Connect to local Weaviate instance\n",
    "    weaviate_client = weaviate.connect_to_local(\n",
    "        host=\"localhost\",\n",
    "        port=8080,\n",
    "        grpc_port=50051\n",
    "    )\n",
    "    \n",
    "    print(\"‚úì Connected to local Weaviate\")\n",
    "    print(\"  Host: localhost:8080\")\n",
    "    print(\"  gRPC Port: 50051\")\n",
    "\n",
    "\n",
    "    # Step 2: Create Weaviate vector store\n",
    "    print(\"\\n\" + \"-\" * 80)\n",
    "    print(\"Creating Weaviate Vector Store\")\n",
    "    print(\"-\" * 80)\n",
    "\n",
    "\n",
    "    weaviate_store = WeaviateVectorStore(\n",
    "        client=weaviate_client,\n",
    "        index_name=\"MyDocument\",\n",
    "        text_key='text',\n",
    "        embedding=embeddings\n",
    "    )\n",
    "\n",
    "    # Step 3: Add documents    \n",
    "    weaviate_store.add_documents(sample_docs)\n",
    "\n",
    "    print(\"‚úì Added documents to Weaviate\")\n",
    "    print(\"  Index: MyDocuments\")\n",
    "    print(\"  Documents: 3\")\n",
    "    \n",
    "    # Step 4: Basic Search\n",
    "    print(\"\\n\" + \"-\" * 80)\n",
    "    print(\"Basic Search\")\n",
    "    print(\"-\" * 80)\n",
    "\n",
    "    result = weaviate_store.similarity_search(\n",
    "        \"Tell me about RAG\",\n",
    "        k=2\n",
    "    )\n",
    "\n",
    "    print(\"\\nQuery: Tell me about RAG\")\n",
    "    print(\"\\nSearch results: \")\n",
    "    for i, doc in enumerate(result,1):\n",
    "        print(f\"{i}. {doc.page_content}\")\n",
    "        print(f\"   Metadata: {doc.metadata}\")\n",
    "\n",
    "    # Step 5: Search with Metadata Filter\n",
    "    print(\"\\n\" + \"-\" * 80)\n",
    "    print(\"Search with Metadata Filter\")\n",
    "    print(\"-\" * 80)\n",
    "\n",
    "    # Weaviate uses where_filter with different syntax\n",
    "    result_filtered = weaviate_store.similarity_search(\n",
    "        \"Tell me about databases\",\n",
    "        k=2,\n",
    "        filters=Filter.by_property(\"difficulty\").equal(\"intermediate\")\n",
    "    )\n",
    "    print(\"\\nQuery: 'Tell me about databases'\")\n",
    "    print(\"Filter: difficulty='intermediate'\")\n",
    "    print(\"\\nFiltered search results:\")\n",
    "\n",
    "    for i, doc in enumerate(result_filtered,1):\n",
    "        print(f\"{i}. {doc.page_content}\")\n",
    "        print(f\"    Metadata: {doc.metadata}\")\n",
    "\n",
    "    # Step 6: Search with Scores\n",
    "    print(\"\\n\" + \"-\" * 80)\n",
    "    print(\"Search with Scores\")\n",
    "    print(\"-\" * 80)\n",
    "    \n",
    "    result_with_scores = weaviate_store.similarity_search_with_score(\n",
    "        \"vector databases\",\n",
    "        k=2\n",
    "    )\n",
    "\n",
    "    print(\"\\nQuery: 'Vector databases'\")\n",
    "    print(\"\\nSearch results with scores:\")\n",
    "    for doc,score in result_with_scores:\n",
    "        print(f\"   Score: {score:.4f}\")\n",
    "        print(f\"   Content: {doc.page_content}\")\n",
    "        print(f\"   Metadata: {doc.metadata}\")\n",
    "\n",
    "    # Step 7: Alternative - Create from Documents\n",
    "    print(\"-\" * 80)\n",
    "    print(\"Creating Weaviate from Documents (Alternative Method)\")\n",
    "    print(\"-\" * 80)\n",
    "\n",
    "    weaviate_store = WeaviateVectorStore.from_documents(\n",
    "        documents=sample_docs,\n",
    "        embedding=embeddings,\n",
    "        client=weaviate_client,\n",
    "        index_name=\"EasyDocuments\"\n",
    "    )\n",
    "    print(\"‚úì Created Weaviate store from documents\")\n",
    "    results = weaviate_store.similarity_search(\"Langchain\", k=2)\n",
    "    print(\"\\nQuick search results:\")\n",
    "    for i, doc in enumerate(results, 1):\n",
    "        print(f\"  {i}. {doc.page_content}\")\n",
    "\n",
    "    weaviate_client.close()\n",
    "    print(\"\\n‚úì Closed Weaviate connection\")\n",
    "\n",
    "\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"‚úó Weaviate error: {e}\")\n",
    "    print()\n",
    "    print(\"Troubleshooting:\")\n",
    "    print(\"1. Check if Weaviate is running: docker ps\")\n",
    "    print(\"2. Start Weaviate: docker run -d -p 8080:8080 -p 50051:50051 \\\\\")\n",
    "    print(\"     --name weaviate cr.weaviate.io/semitechnologies/weaviate:latest\")\n",
    "    print(\"3. Check if port 8080 is available: lsof -i :8080\")\n",
    "    print(\"4. Check Weaviate logs: docker logs weaviate\")\n",
    "    print()\n",
    "    print(\"üí° It's OK if this doesn't work - you can still learn from the code!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cba39e5b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
