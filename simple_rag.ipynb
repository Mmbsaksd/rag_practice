{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "71d81a02",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "from dotenv import load_dotenv\n",
    "from langchain_community.document_loaders import PyPDFLoader\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "from langchain_openai import AzureChatOpenAI, AzureOpenAIEmbeddings\n",
    "from langchain_community.vectorstores import FAISS\n",
    "\n",
    "from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder\n",
    "from langchain_core.messages import HumanMessage, AIMessage\n",
    "from langchain_core.runnables import RunnablePassthrough\n",
    "from langchain_core.output_parsers import StrOutputParser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "353d276c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ AZURE_OPENAI_API_KEY found\n",
      "✅ AZURE_OPENAI_ENDPOINT found\n",
      "✅ AZURE_OPENAI_DEPLOYMENT_NAME found\n",
      "✅ AZURE_OPENAI_API_VERSION found\n",
      "✅ AZURE_OPENAI_EMBEDDING_DEPLOYMENT_NAME found\n"
     ]
    }
   ],
   "source": [
    "load_dotenv()\n",
    "def check_env(var_name):\n",
    "    if os.getenv(var_name):\n",
    "        print(f\"✅ {var_name} found\")\n",
    "    else:\n",
    "        print(\"❌ {var_name} not found — please add it to your .env\")\n",
    "check_env(\"AZURE_OPENAI_API_KEY\")\n",
    "check_env(\"AZURE_OPENAI_ENDPOINT\")\n",
    "check_env(\"AZURE_OPENAI_DEPLOYMENT_NAME\")\n",
    "check_env(\"AZURE_OPENAI_API_VERSION\")\n",
    "check_env(\"AZURE_OPENAI_EMBEDDING_DEPLOYMENT_NAME\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "934098bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PDF Loaded with 15 pages from 'data\\attention.pdf'\n",
      "\n",
      "--- First Document Preview ---\n",
      "Content: Provided proper attribution is provided, Google hereby grants permission to\n",
      "reproduce the tables and figures in this paper solely for use in journalistic or\n",
      "scholarly works.\n",
      "Attention Is All You Need\n",
      "Ashish Vaswani∗\n",
      "Google Brain\n",
      "avaswani@google.com\n",
      "Noam Shazeer∗\n",
      "Google Brain\n",
      "noam@google.com\n",
      "Niki Parmar∗\n",
      "Google Research\n",
      "nikip@google.com\n",
      "Jakob Uszkoreit∗\n",
      "Google Research\n",
      "usz@google.com\n",
      "Llion Jones∗\n",
      "Google Research\n",
      "llion@google.com\n",
      "Aidan N. Gomez∗ †\n",
      "University of Toronto\n",
      "aidan@cs.toronto.edu\n",
      "Łukasz ...\n",
      "Metadata: {'producer': 'pdfTeX-1.40.25', 'creator': 'LaTeX with hyperref', 'creationdate': '2024-04-10T21:11:43+00:00', 'author': '', 'keywords': '', 'moddate': '2024-04-10T21:11:43+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'subject': '', 'title': '', 'trapped': '/False', 'source': 'data\\\\attention.pdf', 'total_pages': 15, 'page': 0, 'page_label': '1'}\n",
      "Total charactors accross all pages: 39587\n"
     ]
    }
   ],
   "source": [
    "path = r'data\\attention.pdf'\n",
    "if not os.path.exists(path):\n",
    "    print(\"ERROR: File '{path}' not found!\")\n",
    "    print(\"Please update with correct PDF path\")\n",
    "else:\n",
    "    loader = PyPDFLoader(path)\n",
    "    documents = loader.load()\n",
    "\n",
    "    print(f\"PDF Loaded with {len(documents)} pages from '{path}'\")\n",
    "    print(\"\\n--- First Document Preview ---\")\n",
    "    print(f\"Content: {documents[0].page_content[:500]}...\")\n",
    "    print(f\"Metadata: {documents[0].metadata}\")\n",
    "    print(f\"Total charactors accross all pages: {sum(len(doc.page_content) for doc in documents)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "40af7198",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 2 PDF files\n",
      "Doc loaded with 15 for attention.pdf\n",
      "Doc loaded with 21 for ragsurvey.pdf\n",
      "\n",
      "Total pages loaded: 36\n"
     ]
    }
   ],
   "source": [
    "#Loading multiple datasets\n",
    "pdf_directory = './data'\n",
    "all_documents = []\n",
    "\n",
    "if os.path.exists(pdf_directory):\n",
    "    pdf_files = list(Path(pdf_directory).glob(\"*.pdf\"))\n",
    "    print(f\"Found {len(pdf_files)} PDF files\")\n",
    "\n",
    "    for pdf_file in pdf_files:\n",
    "        loader = PyPDFLoader(pdf_file)\n",
    "        doc = loader.load()\n",
    "        all_documents.extend(doc)\n",
    "        print(f\"Doc loaded with {len(doc)} for {pdf_file.name}\")\n",
    "    print(f\"\\nTotal pages loaded: {len(all_documents)}\")\n",
    "    documents = all_documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "89a43fdb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Split 36 documents into 180 chunks.\n",
      "Average chunk size: 164183\n",
      "\n",
      "--- Chunks Example---\n",
      "\n",
      "Chunk 1 (length: 986 chars)\n",
      "Provided proper attribution is provided, Google hereby grants permission to\n",
      "reproduce the tables and figures in this paper solely for use in journalistic or\n",
      "scholarly works.\n",
      "Attention Is All You Need\n",
      "...\n",
      "Metadata: {'producer': 'pdfTeX-1.40.25', 'creator': 'LaTeX with hyperref', 'creationdate': '2024-04-10T21:11:43+00:00', 'author': '', 'keywords': '', 'moddate': '2024-04-10T21:11:43+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'subject': '', 'title': '', 'trapped': '/False', 'source': 'data\\\\attention.pdf', 'total_pages': 15, 'page': 0, 'page_label': '1'}\n",
      "\n",
      "Chunk 2 (length: 944 chars)\n",
      "based solely on attention mechanisms, dispensing with recurrence and convolutions\n",
      "entirely. Experiments on two machine translation tasks show these models to\n",
      "be superior in quality while being more pa...\n",
      "Metadata: {'producer': 'pdfTeX-1.40.25', 'creator': 'LaTeX with hyperref', 'creationdate': '2024-04-10T21:11:43+00:00', 'author': '', 'keywords': '', 'moddate': '2024-04-10T21:11:43+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'subject': '', 'title': '', 'trapped': '/False', 'source': 'data\\\\attention.pdf', 'total_pages': 15, 'page': 0, 'page_label': '1'}\n",
      "\n",
      "Chunk 3 (length: 986 chars)\n",
      "∗Equal contribution. Listing order is random. Jakob proposed replacing RNNs with self-attention and started\n",
      "the effort to evaluate this idea. Ashish, with Illia, designed and implemented the first Tra...\n",
      "Metadata: {'producer': 'pdfTeX-1.40.25', 'creator': 'LaTeX with hyperref', 'creationdate': '2024-04-10T21:11:43+00:00', 'author': '', 'keywords': '', 'moddate': '2024-04-10T21:11:43+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'subject': '', 'title': '', 'trapped': '/False', 'source': 'data\\\\attention.pdf', 'total_pages': 15, 'page': 0, 'page_label': '1'}\n"
     ]
    }
   ],
   "source": [
    "text_splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size=1024,\n",
    "    chunk_overlap=128,\n",
    "    length_function=len,\n",
    "    separators=[\"\\n\\n\", \"\\n\", \" \", \"\"]\n",
    ")\n",
    "chunks = text_splitter.split_documents(documents)\n",
    "print(f\"Split {len(documents)} documents into {len(chunks)} chunks.\")\n",
    "print(f\"Average chunk size: {sum(len(chunk.page_content)for chunk in chunks) }\")\n",
    "\n",
    "print(f\"\\n--- Chunks Example---\")\n",
    "for i, chunk in enumerate(chunks[:3]):\n",
    "    print(f\"\\nChunk {i+1} (length: {len(chunk.page_content)} chars)\")\n",
    "    print(f\"{chunk.page_content[:200]}...\")\n",
    "    print(f\"Metadata: {chunk.metadata}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "41e7bff9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Embeddings model initialized: text-embedding-ada-002\n",
      "✓ Embedding dimension: 1536\n",
      "✓ Sample embedding (first 10 values): [-0.018449613824486732, 0.002806746633723378, 0.0020374529995024204, -0.010561833158135414, 0.0018392505589872599, 0.015305251814424992, -0.0036852199118584394, 0.004199202172458172, -0.02843363769352436, -0.026498645544052124]\n",
      "\n",
      "ℹ️  Each chunk will be converted to a 1536-dimensional vector for similarity search\n"
     ]
    }
   ],
   "source": [
    "embeddings = AzureOpenAIEmbeddings(\n",
    "    azure_endpoint=os.getenv(\"AZURE_OPENAI_ENDPOINT\"),\n",
    "    api_key=os.getenv(\"AZURE_OPENAI_API_KEY\"),\n",
    "    api_version=os.getenv(\"AZURE_OPENAI_API_VERSION\"),\n",
    "    model=os.getenv(\"AZURE_OPENAI_EMBEDDING_DEPLOYMENT_NAME\")\n",
    ")\n",
    "sample_text = \"This is the text sentance to demonstrate embeddings\"\n",
    "sample_embedding = embeddings.embed_query(sample_text)\n",
    "\n",
    "print(\"✓ Embeddings model initialized: text-embedding-ada-002\")\n",
    "print(f\"✓ Embedding dimension: {len(sample_embedding)}\")\n",
    "print(f\"✓ Sample embedding (first 10 values): {sample_embedding[:10]}\")\n",
    "print(f\"\\nℹ️  Each chunk will be converted to a {len(sample_embedding)}-dimensional vector for similarity search\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "401d0d8e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating FAISS index from 180 chunks\n",
      "FAISS vector stored successfully!\n",
      "Indexed 180 documents chunks\n",
      "✓ Vector store saved to './faiss_index'\n",
      "\n",
      "ℹ️  You can reload this index later using: FAISS.load_local('./faiss_index', embeddings)\n"
     ]
    }
   ],
   "source": [
    "print(f\"Creating FAISS index from {len(chunks)} chunks\")\n",
    "vectore_store = FAISS.from_documents(\n",
    "    documents=chunks,\n",
    "    embedding=embeddings\n",
    ")\n",
    "print(f\"FAISS vector stored successfully!\")\n",
    "print(f\"Indexed {len(chunks)} documents chunks\")\n",
    "\n",
    "vectorstore_path = \"./faiss_index\"\n",
    "vectore_store.save_local(vectorstore_path)\n",
    "print(f\"✓ Vector store saved to '{vectorstore_path}'\")\n",
    "print(f\"\\nℹ️  You can reload this index later using: FAISS.load_local('{vectorstore_path}', embeddings)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "da0d236a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Loaded existing vector store from './faiss_index'\n"
     ]
    }
   ],
   "source": [
    "vectorstore_path = './faiss_index'\n",
    "vectore_store = FAISS.load_local(\n",
    "    vectorstore_path,\n",
    "    embeddings,\n",
    "    allow_dangerous_deserialization=True\n",
    ")\n",
    "print(f\"✓ Loaded existing vector store from '{vectorstore_path}'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "bcf45e22",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Retriever configured successfully\n",
      "  - Search type: similarity\n",
      "  - Number of documents to retrieve (k): 4\n",
      "\n",
      "--- Retriever Test ---\n",
      "Query: 'What is the main topic of this documents?'\n",
      "Retrieved 4 documents:\n",
      "\n",
      "Documents: 1\n",
      "  Content preview: Table I.\n",
      "B. Indexing Optimization\n",
      "In the Indexing phase, documents will be processed, seg-\n",
      "mented, and transformed into Embeddings to be stored in a\n",
      "v...\n",
      "  Metadata: {'producer': 'pdfTeX-1.40.25', 'creator': 'LaTeX with hyperref', 'creationdate': '2024-03-28T00:54:45+00:00', 'author': '', 'keywords': '', 'moddate': '2024-03-28T00:54:45+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'subject': '', 'title': '', 'trapped': '/False', 'source': 'data\\\\ragsurvey.pdf', 'total_pages': 21, 'page': 7, 'page_label': '8'}\n",
      "\n",
      "Documents: 2\n",
      "  Content preview: caused by block extraction issues.\n",
      "Knowledge Graph index . Utilize KG in constructing the\n",
      "hierarchical structure of documents contributes to maintaini...\n",
      "  Metadata: {'producer': 'pdfTeX-1.40.25', 'creator': 'LaTeX with hyperref', 'creationdate': '2024-03-28T00:54:45+00:00', 'author': '', 'keywords': '', 'moddate': '2024-03-28T00:54:45+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'subject': '', 'title': '', 'trapped': '/False', 'source': 'data\\\\ragsurvey.pdf', 'total_pages': 21, 'page': 7, 'page_label': '8'}\n",
      "\n",
      "Documents: 3\n",
      "  Content preview: effective RAG framework.\n",
      "• We have summarized the current assessment methods of\n",
      "RAG, covering 26 tasks, nearly 50 datasets, outlining\n",
      "the evaluation o...\n",
      "  Metadata: {'producer': 'pdfTeX-1.40.25', 'creator': 'LaTeX with hyperref', 'creationdate': '2024-03-28T00:54:45+00:00', 'author': '', 'keywords': '', 'moddate': '2024-03-28T00:54:45+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'subject': '', 'title': '', 'trapped': '/False', 'source': 'data\\\\ragsurvey.pdf', 'total_pages': 21, 'page': 1, 'page_label': '2'}\n",
      "\n",
      "Documents: 4\n",
      "  Content preview: clude semi-structured data (PDF) and structured data (Knowl-\n",
      "edge Graph, KG) for enhancement. In addition to retrieving\n",
      "from original external sources...\n",
      "  Metadata: {'producer': 'pdfTeX-1.40.25', 'creator': 'LaTeX with hyperref', 'creationdate': '2024-03-28T00:54:45+00:00', 'author': '', 'keywords': '', 'moddate': '2024-03-28T00:54:45+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'subject': '', 'title': '', 'trapped': '/False', 'source': 'data\\\\ragsurvey.pdf', 'total_pages': 21, 'page': 4, 'page_label': '5'}\n"
     ]
    }
   ],
   "source": [
    "retriever = vectore_store.as_retriever(\n",
    "    search_type = \"similarity\",\n",
    "    search_kwargs={\"k\":4}\n",
    ")\n",
    "print(\"✓ Retriever configured successfully\")\n",
    "print(f\"  - Search type: similarity\")\n",
    "print(f\"  - Number of documents to retrieve (k): 4\")\n",
    "\n",
    "test_query = \"What is the main topic of this documents?\"\n",
    "retrieved_docs = retriever.invoke(test_query)\n",
    "\n",
    "print(f\"\\n--- Retriever Test ---\")\n",
    "print(f\"Query: '{test_query}'\")\n",
    "print(f\"Retrieved {len(retrieved_docs)} documents:\")\n",
    "\n",
    "for i, doc in enumerate(retrieved_docs):\n",
    "    print(f\"\\nDocuments: {i+1}\")\n",
    "    print(f\"  Content preview: {doc.page_content[:150]}...\")\n",
    "    print(f\"  Metadata: {doc.metadata}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f9c22ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ LLM configured successfully\n",
      "  - Model: gpt-4-o\n",
      "  - Temperature: 0 (deterministic)\n",
      "  - Max tokens: 2000\n"
     ]
    }
   ],
   "source": [
    "llm = AzureChatOpenAI(\n",
    "    api_key=os.getenv(\"AZURE_OPENAI_API_KEY\"),\n",
    "    azure_endpoint=os.getenv(\"AZURE_OPENAI_ENDPOINT\"),\n",
    "    api_version=os.getenv(\"AZURE_OPENAI_API_VERSION\"),\n",
    "    deployment_name=os.getenv(\"AZURE_OPENAI_DEPLOYMENT_NAME\"),\n",
    "    temperature=0.0,\n",
    "    max_tokens=2000,\n",
    ")\n",
    "print(\"✓ LLM configured successfully\")\n",
    "print(f\"  - Model: gpt-4-o\")\n",
    "print(f\"  - Temperature: 0 (deterministic)\")\n",
    "print(f\"  - Max tokens: 2000\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "d9d37e29",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ RAG chain created successfully using LangChain 1.0+ LCEL!\n",
      "\n",
      "RAG Pipeline Flow:\n",
      "  1. User provides a query\n",
      "  2. Retriever finds top 4 relevant chunks\n",
      "  3. Chunks are formatted as context\n",
      "  4. Context + question are formatted with prompt template\n",
      "  5. LLM generates answer based on context\n",
      "  6. Answer is parsed and returned to user\n"
     ]
    }
   ],
   "source": [
    "system_prompt = (\n",
    "    \"You are a helpful assistant for question-answering tasks. \"\n",
    "    \"Use the following pieces of retrieved context to answer the question. \"\n",
    "    \"If you don't know the answer based on the context, say that you don't know. \"\n",
    "    \"Keep the answer concise and accurate.\\n\\n\"\n",
    "    \"Context: {context}\\n\\n\"\n",
    "    \"Question: {question}\"   \n",
    ")\n",
    "prompt = ChatPromptTemplate.from_template(system_prompt)\n",
    "\n",
    "def format_docs(docs):\n",
    "    return \"\\n\\n\".join(doc.page_content for doc in docs)\n",
    "\n",
    "rag_chain = (\n",
    "    {\n",
    "        \"context\":retriever | format_docs,\n",
    "        \"question\": RunnablePassthrough()\n",
    "    }\n",
    "    | prompt\n",
    "    | llm\n",
    "    | StrOutputParser()\n",
    ")\n",
    "print(\"✓ RAG chain created successfully using LangChain 1.0+ LCEL!\")\n",
    "print(\"\\nRAG Pipeline Flow:\")\n",
    "print(\"  1. User provides a query\")\n",
    "print(\"  2. Retriever finds top 4 relevant chunks\")\n",
    "print(\"  3. Chunks are formatted as context\")\n",
    "print(\"  4. Context + question are formatted with prompt template\")\n",
    "print(\"  5. LLM generates answer based on context\")\n",
    "print(\"  6. Answer is parsed and returned to user\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "f5af6da6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query: What is the main topic or subject of this documents\n",
      "\n",
      "\n",
      "Processing...\n",
      "\n",
      "================================================================================\n",
      "ANSWER:\n",
      "================================================================================\n",
      "The main topic of the document is optimization techniques for indexing and retrieval in information systems, focusing on strategies like chunking, recursive splits, sliding windows, and the use of Knowledge Graphs (KG) to enhance semantic completeness, context length, and retrieval accuracy. It also discusses methods for improving the efficiency of retrieval-augmented generation (RAG) systems.\n",
      "\n",
      "================================================================================\n",
      "\n",
      "Document: 1\n",
      "   Source: {'producer': 'pdfTeX-1.40.25', 'creator': 'LaTeX with hyperref', 'creationdate': '2024-03-28T00:54:45+00:00', 'author': '', 'keywords': '', 'moddate': '2024-03-28T00:54:45+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'subject': '', 'title': '', 'trapped': '/False', 'source': 'data\\\\ragsurvey.pdf', 'total_pages': 21, 'page': 7, 'page_label': '8'}\n",
      "   Content: Table I.\n",
      "B. Indexing Optimization\n",
      "In the Indexing phase, documents will be processed, seg-\n",
      "mented, and transformed into Embeddings to be stored in a\n",
      "vector database. The quality of index construction \n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "Document: 2\n",
      "   Source: {'producer': 'pdfTeX-1.40.25', 'creator': 'LaTeX with hyperref', 'creationdate': '2024-03-28T00:54:45+00:00', 'author': '', 'keywords': '', 'moddate': '2024-03-28T00:54:45+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'subject': '', 'title': '', 'trapped': '/False', 'source': 'data\\\\ragsurvey.pdf', 'total_pages': 21, 'page': 7, 'page_label': '8'}\n",
      "   Content: caused by block extraction issues.\n",
      "Knowledge Graph index . Utilize KG in constructing the\n",
      "hierarchical structure of documents contributes to maintaining\n",
      "consistency. It delineates the connections betw\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "Document: 3\n",
      "   Source: {'producer': 'pdfTeX-1.40.25', 'creator': 'LaTeX with hyperref', 'creationdate': '2024-04-10T21:11:43+00:00', 'author': '', 'keywords': '', 'moddate': '2024-04-10T21:11:43+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'subject': '', 'title': '', 'trapped': '/False', 'source': 'data\\\\attention.pdf', 'total_pages': 15, 'page': 14, 'page_label': '15'}\n",
      "   Content: Input-Input Layer5\n",
      "The\n",
      "Law\n",
      "will\n",
      "never\n",
      "be\n",
      "perfect\n",
      ",\n",
      "but\n",
      "its\n",
      "application\n",
      "should\n",
      "be\n",
      "just\n",
      "-\n",
      "this\n",
      "is\n",
      "what\n",
      "we\n",
      "are\n",
      "missing\n",
      ",\n",
      "in\n",
      "my\n",
      "opinion\n",
      ".\n",
      "<EOS>\n",
      "<pad>\n",
      "The\n",
      "Law\n",
      "will\n",
      "never\n",
      "be\n",
      "perfect\n",
      ",\n",
      "but\n",
      "its\n",
      "application\n",
      "sh\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "Document: 4\n",
      "   Source: {'producer': 'pdfTeX-1.40.25', 'creator': 'LaTeX with hyperref', 'creationdate': '2024-03-28T00:54:45+00:00', 'author': '', 'keywords': '', 'moddate': '2024-03-28T00:54:45+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'subject': '', 'title': '', 'trapped': '/False', 'source': 'data\\\\ragsurvey.pdf', 'total_pages': 21, 'page': 19, 'page_label': '20'}\n",
      "   Content: just the summary! topic-aware convolutional neural networks for ex-\n",
      "treme summarization,” arXiv preprint arXiv:1808.08745 , 2018.\n",
      "[154] S. Saha, J. A. Junaed, M. Saleki, A. S. Sharma, M. R. Rifat, M. \n",
      "--------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "query1 = \"What is the main topic or subject of this documents\"\n",
    "print(f\"Query: {query1}\\n\")\n",
    "print(f\"\\nProcessing...\\n\")\n",
    "\n",
    "answer = rag_chain.invoke(query1)\n",
    "\n",
    "print(\"=\" * 80)\n",
    "print(\"ANSWER:\")\n",
    "print(\"=\" * 80)\n",
    "print(answer)\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "retrieved_docs = retriever.invoke(query1)\n",
    "for i, doc in enumerate(retrieved_docs):\n",
    "    print(f\"\\nDocument: {i+1}\")\n",
    "    print(f\"   Source: {doc.metadata}\")\n",
    "    print(f\"   Content: {doc.page_content[:200]}\")\n",
    "    print(\"-\"*80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "8e09510d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query: Can you summarize the key points from this document?\n",
      "\n",
      "Processing...\n",
      "\n",
      "================================================================================\n",
      "ANSWER:\n",
      "================================================================================\n",
      "The document discusses the current state and future directions of the Retrieval-Augmented Generation (RAG) framework. Key points include:\n",
      "\n",
      "1. **Assessment and Evaluation**: The paper summarizes assessment methods for RAG across 26 tasks and nearly 50 datasets, detailing evaluation objectives, metrics, benchmarks, and tools.\n",
      "\n",
      "2. **Core Components**: It explores the three main components of RAG:\n",
      "   - **Retrieval**: Optimization methods like indexing, query, and embedding improvements.\n",
      "   - **Generation**: Post-retrieval processes and fine-tuning of large language models (LLMs).\n",
      "   - **Augmentation**: Analysis of augmentation processes, including metadata enrichment and content generation.\n",
      "\n",
      "3. **Enhancements**: \n",
      "   - Use of semi-structured (e.g., PDFs) and structured data (e.g., Knowledge Graphs) for improvement.\n",
      "   - Trends in using LLM-generated content for retrieval and enhancement.\n",
      "\n",
      "4. **Challenges and Innovations**:\n",
      "   - Balancing semantic completeness and context length, with methods like Small2Big providing contextual information.\n",
      "   - Metadata enrichment (e.g., timestamps, summaries, hypothetical questions) for improved retrieval, including time-aware RAG.\n",
      "\n",
      "5. **Future Directions**: The paper highlights challenges and potential advancements to address current limitations in RAG systems.\n",
      "\n",
      "================================================================================\n"
     ]
    }
   ],
   "source": [
    "query2 = \"Can you summarize the key points from this document?\"\n",
    "\n",
    "print(f\"Query: {query2}\")\n",
    "print(\"\\nProcessing...\\n\")\n",
    "\n",
    "answer = rag_chain.invoke(query2)\n",
    "\n",
    "print(\"=\" * 80)\n",
    "print(\"ANSWER:\")\n",
    "print(\"=\" * 80)\n",
    "print(answer)\n",
    "print(\"\\n\" + \"=\" * 80)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
