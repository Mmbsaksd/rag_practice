{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3f47c454",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ AZURE_OPENAI_API_KEY found\n",
      "✅ AZURE_OPENAI_ENDPOINT found\n",
      "✅ AZURE_OPENAI_DEPLOYMENT_NAME found\n",
      "✅ AZURE_OPENAI_API_VERSION found\n",
      "✅ GOOGLE_API_KEY found\n"
     ]
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "import os\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "def check_env(var_name):\n",
    "    if os.getenv(var_name):\n",
    "        print(f\"✅ {var_name} found\")\n",
    "    else:\n",
    "        print(f\"❌ {var_name} not found — please add it to your .env\")\n",
    "\n",
    "check_env(\"AZURE_OPENAI_API_KEY\")\n",
    "check_env(\"AZURE_OPENAI_ENDPOINT\")\n",
    "check_env(\"AZURE_OPENAI_DEPLOYMENT_NAME\")\n",
    "check_env(\"AZURE_OPENAI_API_VERSION\")\n",
    "check_env(\"GOOGLE_API_KEY\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a59f5f7e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Content: \n",
      " LangChain makes building LLM applications easy!\n",
      "\n",
      "Metadata: \n",
      " {'source': 'introduction.txt', 'author': 'LangChain Team', 'date': '2025-01-15'}\n"
     ]
    }
   ],
   "source": [
    "from langchain_core.documents import Document\n",
    "doc = Document(\n",
    "    page_content=\"LangChain makes building LLM applications easy!\",\n",
    "    metadata={\n",
    "        \"source\": \"introduction.txt\",\n",
    "        \"author\": \"LangChain Team\",\n",
    "        \"date\": \"2025-01-15\"\n",
    "    }\n",
    ")\n",
    "\n",
    "print(\"Content: \\n\", doc.page_content)\n",
    "print(\"\\nMetadata: \\n\", doc.metadata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cd8005c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++\n",
      " Document: 1\n",
      "Content:  Python is a high-level programming language.\n",
      "Category:  programming\n",
      "Difficulty:  beginner\n",
      "************************************************************\n",
      "++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++\n",
      " Document: 2\n",
      "Content:  Machine learning is a subset of artificial intelligence.\n",
      "Category:  AI\n",
      "Difficulty:  intermediate\n",
      "************************************************************\n",
      "++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++\n",
      " Document: 3\n",
      "Content:  RAG combines retrieval and generation for better LLM outputs.\n",
      "Category:  AI\n",
      "Difficulty:  advanced\n",
      "************************************************************\n"
     ]
    }
   ],
   "source": [
    "documents =[\n",
    "    Document(\n",
    "        page_content=\"Python is a high-level programming language.\",\n",
    "        metadata={\"category\": \"programming\", \"difficulty\": \"beginner\"}\n",
    "    ),\n",
    "    Document(\n",
    "        page_content=\"Machine learning is a subset of artificial intelligence.\",\n",
    "        metadata={\"category\": \"AI\", \"difficulty\": \"intermediate\"}\n",
    "    ),\n",
    "    Document(\n",
    "        page_content=\"RAG combines retrieval and generation for better LLM outputs.\",\n",
    "        metadata={\"category\": \"AI\", \"difficulty\": \"advanced\"}\n",
    "    )\n",
    "]\n",
    "\n",
    "for i, doc in enumerate(documents,1):\n",
    "    print(\"+\"*60)\n",
    "    print(f\" Document: {i}\")\n",
    "    print(f\"Content: \", doc.page_content)\n",
    "    print(f\"Category: \",doc.metadata['category'])\n",
    "    print(f\"Difficulty: \", doc.metadata['difficulty'])\n",
    "    print(\"*\"*60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d9524be2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input: hello langchain\n",
      "  Step 1: uppercase → HELLO LANGCHAIN\n",
      "  Step 2: add_prefix → RESULT: HELLO LANGCHAIN\n",
      "  Step 3: add_emoji → ✅ RESULT: HELLO LANGCHAIN\n",
      "Output: ✅ RESULT: HELLO LANGCHAIN\n"
     ]
    }
   ],
   "source": [
    "from langchain_core.runnables import RunnableLambda\n",
    "\n",
    "def uppercase(text: str) -> str:\n",
    "    \"\"\"Convert text to uppercase\"\"\"\n",
    "    print(f\"  Step 1: uppercase → {text.upper()}\")\n",
    "    return text.upper()\n",
    "\n",
    "def add_prefix(text: str) -> str:\n",
    "    \"\"\"Add a prefix to text\"\"\"\n",
    "    result = f\"RESULT: {text}\"\n",
    "    print(f\"  Step 2: add_prefix → {result}\")\n",
    "    return result\n",
    "\n",
    "def add_emoji(text: str) -> str:\n",
    "    \"\"\"Add emoji to text\"\"\"\n",
    "    result = f\"✅ {text}\"\n",
    "    print(f\"  Step 3: add_emoji → {result}\")\n",
    "    return result\n",
    "\n",
    "uppercase_runnable = RunnableLambda(uppercase)\n",
    "prefix_runnable = RunnableLambda(add_prefix)\n",
    "emoji_runnable = RunnableLambda(add_emoji)\n",
    "\n",
    "chain = uppercase_runnable|prefix_runnable|emoji_runnable\n",
    "\n",
    "print(\"Input: hello langchain\")\n",
    "result = chain.invoke(\"hello langchain\")\n",
    "print(f\"Output: {result}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4568ba84",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question: What is LangChain in one sentence?\n",
      "\n",
      "Answer: LangChain is a framework for building applications powered by language models, enabling seamless integration with data sources, custom workflows, and external tools to create advanced AI-driven solutions.\n"
     ]
    }
   ],
   "source": [
    "from langchain_openai import AzureChatOpenAI\n",
    "\n",
    "llm = AzureChatOpenAI(\n",
    "    azure_endpoint=os.getenv(\"AZURE_OPENAI_ENDPOINT\"),\n",
    "    api_key=os.getenv(\"AZURE_OPENAI_API_KEY\"),\n",
    "    deployment_name=os.getenv(\"AZURE_OPENAI_DEPLOYMENT_NAME\"),\n",
    "    api_version=os.getenv(\"AZURE_OPENAI_API_VERSION\"),\n",
    ")\n",
    "\n",
    "response = llm.invoke(\"What is LangChain in one sentence?\")\n",
    "print(\"Question: What is LangChain in one sentence?\")\n",
    "print(f\"\\nAnswer: {response.content}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d16dc860",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Response Type: <class 'langchain_core.messages.ai.AIMessage'>\n",
      "\n",
      "Content: LangChain is a framework for building applications powered by language models, enabling seamless integration with data sources, custom workflows, and external tools to create advanced AI-driven solutions.\n",
      "\n",
      "Response Metadata:\n",
      "{'token_usage': {'completion_tokens': 34, 'prompt_tokens': 15, 'total_tokens': 49, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_provider': 'openai', 'model_name': 'gpt-4o-2024-11-20', 'system_fingerprint': 'fp_b54fe76834', 'id': 'chatcmpl-CorG483CGXlCxyP7mu3FI2P0rQi0B', 'prompt_filter_results': [{'prompt_index': 0, 'content_filter_results': {'hate': {'filtered': False, 'severity': 'safe'}, 'jailbreak': {'filtered': False, 'detected': False}, 'self_harm': {'filtered': False, 'severity': 'safe'}, 'sexual': {'filtered': False, 'severity': 'safe'}, 'violence': {'filtered': False, 'severity': 'safe'}}}], 'finish_reason': 'stop', 'logprobs': None, 'content_filter_results': {'hate': {'filtered': False, 'severity': 'safe'}, 'protected_material_code': {'filtered': False, 'detected': False}, 'protected_material_text': {'filtered': False, 'detected': False}, 'self_harm': {'filtered': False, 'severity': 'safe'}, 'sexual': {'filtered': False, 'severity': 'safe'}, 'violence': {'filtered': False, 'severity': 'safe'}}}\n"
     ]
    }
   ],
   "source": [
    "print(\"Response Type:\", type(response))\n",
    "print(\"\\nContent:\", response.content)\n",
    "print(\"\\nResponse Metadata:\")\n",
    "print(response.response_metadata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ea00a8ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token Used: \n",
      "   Prompt: 15\n",
      "   Completion: 34\n",
      "   Total: 49\n"
     ]
    }
   ],
   "source": [
    "if 'token_usage' in response.response_metadata:\n",
    "    usage = response.response_metadata['token_usage']\n",
    "    print(\"Token Used: \")\n",
    "    print(f\"   Prompt: {usage.get('prompt_tokens')}\")\n",
    "    print(f\"   Completion: {usage.get('completion_tokens')}\")\n",
    "    print(f\"   Total: {usage.get('total_tokens')}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9058de4c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question: What is LangChain in one sentence?\n",
      "\n",
      "Answer: LangChain is a development framework that simplifies building applications and agents powered by large language models by connecting them with external data, computations, and other tools.\n"
     ]
    }
   ],
   "source": [
    "from langchain_google_genai import ChatGoogleGenerativeAI\n",
    "\n",
    "llm = ChatGoogleGenerativeAI(\n",
    "    model =  \"gemini-2.5-flash\",\n",
    "    temperature=0\n",
    ")\n",
    "\n",
    "response = llm.invoke(\"What is LangChain in one sentence?\")\n",
    "print(\"Question: What is LangChain in one sentence?\")\n",
    "print(f\"\\nAnswer: {response.content}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5efb3d51",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Response Type: <class 'langchain_core.messages.ai.AIMessage'>\n",
      "\n",
      "Content: LangChain is a development framework that simplifies building applications and agents powered by large language models by connecting them with external data, computations, and other tools.\n",
      "\n",
      "Response Metadata:\n",
      "{'finish_reason': 'STOP', 'model_name': 'gemini-2.5-flash', 'safety_ratings': [], 'model_provider': 'google_genai'}\n"
     ]
    }
   ],
   "source": [
    "print(\"Response Type:\", type(response))\n",
    "print(\"\\nContent:\", response.content)\n",
    "print(\"\\nResponse Metadata:\")\n",
    "print(response.response_metadata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "16514543",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input_variables=['topic'] input_types={} partial_variables={} messages=[HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['topic'], input_types={}, partial_variables={}, template='Explain {topic} in simple terms suitable for beginners in 200 words.'), additional_kwargs={})]\n",
      "==============================\n",
      "[HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['topic'], input_types={}, partial_variables={}, template='Explain {topic} in simple terms suitable for beginners in 200 words.'), additional_kwargs={})]\n",
      "==============================\n",
      "prompt=PromptTemplate(input_variables=['topic'], input_types={}, partial_variables={}, template='Explain {topic} in simple terms suitable for beginners in 200 words.') additional_kwargs={}\n",
      "==============================\n",
      "input_variables=['topic'] input_types={} partial_variables={} template='Explain {topic} in simple terms suitable for beginners in 200 words.'\n",
      "==============================\n",
      "Explain {topic} in simple terms suitable for beginners in 200 words.\n"
     ]
    }
   ],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "\n",
    "prompt_format = \"Explain {topic} in simple terms suitable for beginners in 200 words.\"\n",
    "prompt = ChatPromptTemplate.from_template(prompt_format)\n",
    "\n",
    "print(prompt)\n",
    "print(\"=\"*30)\n",
    "print(prompt.messages)\n",
    "print(\"=\"*30)\n",
    "print(prompt.messages[0])\n",
    "print(\"=\"*30)\n",
    "print(prompt.messages[0].prompt)\n",
    "print(\"=\"*30)\n",
    "print(prompt.messages[0].prompt.template)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "a17b4fef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "Topic:  MACHINE LEARNING\n",
      "============================================================\n",
      "Machine learning is a way for computers to learn and make decisions without being explicitly programmed. Instead of following a fixed set of instructions, a computer analyzes data, identifies patterns, and uses those patterns to make predictions or solve problems.\n",
      "\n",
      "Think of it like teaching a child to recognize fruits. You show them many examples of apples and bananas and explain the differences. Over time, the child learns to identify them based on their shapes, colors, and sizes. Similarly, in machine learning, we \"train\" a computer by feeding it lots of data (e.g., images of apples and bananas) so it can learn to identify or classify new data.\n",
      "\n",
      "There are three main types of machine learning:\n",
      "\n",
      "1. **Supervised learning**: The computer is given labeled data (e.g., pictures labeled as \"apple\" or \"banana\") and learns the relationship between the data and the labels.\n",
      "2. **Unsupervised learning**: The computer works with unlabeled data, finding patterns or groups (e.g., grouping similar images without knowing what they are).\n",
      "3. **Reinforcement learning**: The computer learns by trial and error, like a video game, improving through rewards or penalties.\n",
      "\n",
      "From recognizing speech to recommending products, machine learning powers many technologies you use daily. It helps computers get smarter by learning from experience!\n",
      "============================================================\n",
      "Topic:  EMBEDDINGS\n",
      "============================================================\n",
      "Embeddings are a way to represent complex data, like words or pictures, as numbers so that computers can understand and work with them. Think of an embedding as translating information into a simpler form — like turning a word into coordinates on a map. These coordinates help capture the meaning or similarity between items in a way that machines can process.\n",
      "\n",
      "For example, in language, the word \"king\" might be represented as numbers like (5.7, 2.1), and \"queen\" as (5.8, 2.2). These points are close together, meaning the words are related. Meanwhile, an unrelated word like \"banana\" might have coordinates far away, like (0.2, 8.1). This closeness or distance between points reflects relationships between concepts.\n",
      "\n",
      "Embeddings are powerful because they help computers analyze complicated things like text, images, or music in a mathematical way. They are widely used in tasks like language translation, search engines, and image recognition. By converting data into meaningful numbers, embeddings allow computers to \"understand\" patterns and similarities, making machine learning algorithms more efficient and effective. \n",
      "\n",
      "In simple terms, embeddings turn ideas into numbers, keeping the important relationships intact so machines can work with them.\n",
      "============================================================\n",
      "Topic:  VECTOR DATABASES\n",
      "============================================================\n",
      "Sure! Traditional databases store and organize information like text, numbers, or rows of data that can be easily searched using specific keywords. But, some types of data — like images, videos, or audio — can’t be searched using simple keywords. That’s where vector databases become useful.\n",
      "\n",
      "In simple terms, a vector database stores data in the form of vectors. A vector is just a list of numbers that represents a piece of data, like an image, word, or audio file. These numbers are created by converting data into a mathematical format using machine learning models. This method captures the key features or meaning of the data. For example, the vector of a cat picture might represent its shape, colors, or other characteristics.\n",
      "\n",
      "Once data is stored as vectors, the database helps find similar items by comparing these vectors. This is perfect for tasks like searching for images similar to one you upload, or finding related words, songs, or recommendations. Instead of exact matches, vector databases focus on “similarity” searches, which makes them great for modern AI applications like chatbots, recommendation systems, and image recognition.\n",
      "\n",
      "So, vectors transform how we store and search complex data, enabling more intelligent and intuitive applications!\n"
     ]
    }
   ],
   "source": [
    "from langchain_core.output_parsers import StrOutputParser\n",
    "\n",
    "chain = prompt | llm | StrOutputParser()\n",
    "topics = [\"machine learning\", \"embeddings\", \"vector databases\"]\n",
    "\n",
    "for topic in topics:\n",
    "    print(\"=\"*60)\n",
    "    print(f\"Topic: \", topic.upper())\n",
    "    print(\"=\"*60)\n",
    "\n",
    "    explanation = chain.invoke({\"topic\":topic})\n",
    "    print(explanation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "fdaef44a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "1. RAG:\n",
      "   RAG, which stands for Retrieval-Augmented Generation, is a method used to improve how AI generates r...\n",
      "\n",
      "2. LCEL:\n",
      "   LCEL stands for **Low-Carbon Energy Label**. It’s a label or certification that is used to show how ...\n",
      "\n",
      "3. LANGCHAIN AGENTS:\n",
      "   LangChain agents are like smart helpers designed to solve tasks by deciding the best tools or action...\n"
     ]
    }
   ],
   "source": [
    "topics_batch = [\n",
    "    {\"topic\": \"RAG\"},\n",
    "    {\"topic\": \"LCEL\"},\n",
    "    {\"topic\": \"LangChain agents\"}\n",
    "]\n",
    "\n",
    "results = chain.batch(topics_batch)\n",
    "\n",
    "for i, (input_dict, result) in enumerate(zip(topics_batch, results), 1):\n",
    "    print(f\"\\n{i}. {input_dict['topic'].upper()}:\")\n",
    "    print(f\"   {result[:100]}...\")  "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
